{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d440102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'pealim', using template directory '/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/scrapy/templates/project', created in:\n",
      "    /Users/pabloherrero/Documents/ManHatTan/mht/notebooks/pealim\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd pealim\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject pealim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36004189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaeb7854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PealimVerbSpider(scrapy.Spider):\n",
    "    name = \"pealim_verb\"\n",
    "    allowed_domains = [\"pealim.com\"]\n",
    "\n",
    "    def start_requests(self):\n",
    "        query = getattr(self, 'verb', None)\n",
    "        if not query:\n",
    "            self.logger.error(\"Please pass ?verb=ללכת\")\n",
    "            return\n",
    "        url = f\"https://www.pealim.com/search/?q={query}\"\n",
    "        yield scrapy.Request(url, self.parse_search)\n",
    "\n",
    "    def parse_search(self, response):\n",
    "        for sel in response.css('li'):\n",
    "            href = sel.css('a::attr(href)').get()\n",
    "            if href and href.startswith('/dict/'):\n",
    "                text = sel.css('a::text').get()\n",
    "                # Optional: ensure text (e.g. infinitive form) matches criteria\n",
    "                yield response.follow(href, self.parse_verb)\n",
    "\n",
    "    def parse_verb(self, response):\n",
    "        verb = response.css('h1 ::text').get()\n",
    "        tables = {}\n",
    "        for part in ['INF', 'PST', 'FUT']:\n",
    "            sel = response.css(f'#h-{part}-L').xpath('following-sibling::table[1]')\n",
    "            headings = sel.css('thead tr th::text').getall()\n",
    "            rows = []\n",
    "            for tr in sel.css('tbody tr'):\n",
    "                row = tr.css('td::text').getall()\n",
    "                rows.append(row)\n",
    "            tables[part] = {\n",
    "                'headings': headings,\n",
    "                'rows': rows\n",
    "            }\n",
    "        yield {\n",
    "            'verb': verb,\n",
    "            'conjugations': tables\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c8421",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m\n\u001b[1;32m     25\u001b[0m process \u001b[38;5;241m=\u001b[39m CrawlerProcess(settings\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOG_LEVEL\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFEEDS\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults.json\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     29\u001b[0m     }\n\u001b[1;32m     30\u001b[0m })\n\u001b[1;32m     31\u001b[0m process\u001b[38;5;241m.\u001b[39mcrawl(PealimSearchSpider, verb\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mללכת\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# this blocks until done\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Load and display results\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scrapy/crawler.py:502\u001b[0m, in \u001b[0;36mCrawlerProcess.start\u001b[0;34m(self, stop_after_crawl, install_signal_handlers)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m install_signal_handlers:\n\u001b[1;32m    499\u001b[0m     reactor\u001b[38;5;241m.\u001b[39maddSystemEventTrigger(\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartup\u001b[39m\u001b[38;5;124m\"\u001b[39m, install_shutdown_handlers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_shutdown\n\u001b[1;32m    501\u001b[0m     )\n\u001b[0;32m--> 502\u001b[0m \u001b[43mreactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstallSignalHandlers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstall_signal_handlers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/twisted/internet/asyncioreactor.py:253\u001b[0m, in \u001b[0;36mAsyncioSelectorReactor.run\u001b[0;34m(self, installSignalHandlers)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, installSignalHandlers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartRunning(installSignalHandlers\u001b[38;5;241m=\u001b[39minstallSignalHandlers)\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_asyncioEventloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_forever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_justStopped:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_justStopped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py:586\u001b[0m, in \u001b[0;36mBaseEventLoop.run_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until stop() is called.\"\"\"\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_coroutine_origin_tracking(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debug)\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_id \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mget_ident()\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py:578\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 578\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 11:06:20 [py.warnings] WARNING: /Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: __main__.PealimSearchSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html\n",
      "  warn(\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import json\n",
    "\n",
    "class PealimSearchSpider(scrapy.Spider):\n",
    "    name = \"pealim_search\"\n",
    "    allowed_domains = [\"pealim.com\"]\n",
    "\n",
    "    def __init__(self, verb=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.verb = verb\n",
    "\n",
    "    def start_requests(self):\n",
    "        url = f\"https://www.pealim.com/search/?q={self.verb}\"\n",
    "        yield scrapy.Request(url, self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        for sel in response.css(\"li.search-result\"):\n",
    "            yield {\n",
    "                \"title\": sel.css(\"a::text\").get(),\n",
    "                \"url\": response.urljoin(sel.css(\"a::attr(href)\").get())\n",
    "            }\n",
    "\n",
    "# Set up and run the spider\n",
    "process = CrawlerProcess(settings={\n",
    "    \"LOG_LEVEL\": \"WARNING\",\n",
    "    \"FEEDS\": {\n",
    "        \"results.json\": {\"format\": \"json\"}\n",
    "    }\n",
    "})\n",
    "process.crawl(PealimSearchSpider, verb=\"ללכת\")\n",
    "process.start()  # this blocks until done\n",
    "\n",
    "# Load and display results\n",
    "with open(\"results.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[:5]  # show up to first 5 results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b92c3fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from hebrew import Hebrew\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29a18162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb_link(hebrew_verb):\n",
    "    search_url = f\"https://www.pealim.com/search/?q={hebrew_verb}\"\n",
    "    r = requests.get(search_url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    # Extract all verb entries from the soup\n",
    "    verb_entries = []\n",
    "\n",
    "    for entry in soup.select('.verb-search-result'):\n",
    "        lemma = entry.select_one('.verb-search-lemma a')\n",
    "        binyan = entry.select_one('.verb-search-binyan')\n",
    "        if 'verb' in binyan.get_text(strip=True).lower():\n",
    "        \n",
    "            if lemma:\n",
    "                text = lemma.get_text(strip=True)\n",
    "                url = lemma['href']\n",
    "                verb_entries.append({'text': text, 'url': url})\n",
    "\n",
    "    first_url = verb_entries[0]['url'] if verb_entries else None\n",
    "    return \"https://www.pealim.com\" + first_url if first_url else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7153759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conjugation_dict(verb_url):\n",
    "    if not verb_url:\n",
    "        return {}\n",
    "    r = requests.get(verb_url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    conjugation_entries = soup.select('.conj-td')\n",
    "\n",
    "    conjug_dict = {}\n",
    "    for entry in conjugation_entries:\n",
    "        for div in entry.find_all('div', id=True):\n",
    "            menukad = div.find('span', class_='menukad')\n",
    "            if menukad:\n",
    "                conjugated_verb_nikkud = menukad.get_text(strip=True)\n",
    "                verb_noniqqud = Hebrew(conjugated_verb_nikkud).no_niqqud()\n",
    "                conjug_dict[div['id']] = verb_noniqqud\n",
    "    return conjug_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "64824f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "hebrew_verb = \"ללכת\"\n",
    "verb_url = get_verb_link(\"לראות\") \n",
    "verb_url = get_verb_link(hebrew_verb) \n",
    "conj_dict = get_conjugation_dict(verb_url)  \n",
    "\n",
    "# Remove all items from ex_dict whose key contains 'IMP' (imperative forms)\n",
    "conj_dict = {k: v for k, v in conj_dict.items() if 'IMP-' not in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0f163a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "conjugation_key_map = {\n",
    "\t\"AP\": \"Present\",\n",
    "\t\"PERF\": \"Past\",\n",
    "\t\"IMPF\": \"Future\",\n",
    "\t\"IMP\": \"Imperative\",\n",
    "\t\"INF\": \"Infinitive\",\n",
    "\t\"ms\": \"masculine singular\",\n",
    "\t\"fs\": \"feminine singular\",\n",
    "\t\"mp\": \"masculine plural\",\n",
    "\t\"fp\": \"feminine plural\",\n",
    "\t\"1s\": \"1st person singular\",\n",
    "\t\"1p\": \"1st person plural\",\n",
    "\t\"2ms\": \"2nd person masculine singular\",\n",
    "\t\"2fs\": \"2nd person feminine singular\",\n",
    "\t\"2mp\": \"2nd person masculine plural\",\n",
    "\t\"2fp\": \"2nd person feminine plural\",\n",
    "\t\"3ms\": \"3rd person masculine singular\",\n",
    "\t\"3fs\": \"3rd person feminine singular\",\n",
    "\t\"3mp\": \"3rd person masculine plural\",\n",
    "\t\"3fp\": \"3rd person feminine plural\",\n",
    "    \"3p\": \"3rd person plural\",\n",
    "\t\"L\": \"long form\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4c8753e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conjugation_key(key, key_map):\n",
    "    \"\"\"Split the key by dash and map each part using key_map if possible.\"\"\"\n",
    "    parts = key.split('-')\n",
    "    mapped_parts = [key_map.get(part, part) for part in parts]\n",
    "    return \" - \".join(mapped_parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2371b907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random conjugation for 'ללכת':\n",
      "Past - 1st person plural: הלכנו\n"
     ]
    }
   ],
   "source": [
    "key, value = random.choice(list(conj_dict.items()))\n",
    "parsed_key = parse_conjugation_key(key, conjugation_key_map)\n",
    "print(f\"Random conjugation for '{hebrew_verb}':\")\n",
    "print(f\"{parsed_key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ccc6fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP-ms: Present - masculine singular = הולך\n",
      "AP-fs: Present - feminine singular = הולכת\n",
      "AP-mp: Present - masculine plural = הולכים\n",
      "AP-fp: Present - feminine plural = הולכות\n",
      "PERF-1s: Past - 1st person singular = הלכתי\n",
      "PERF-1p: Past - 1st person plural = הלכנו\n",
      "PERF-2ms: Past - 2nd person masculine singular = הלכת\n",
      "PERF-2fs: Past - 2nd person feminine singular = הלכת\n",
      "PERF-2mp: Past - 2nd person masculine plural = הלכתם\n",
      "PERF-2fp: Past - 2nd person feminine plural = הלכתן\n",
      "PERF-3ms: Past - 3rd person masculine singular = הלך\n",
      "PERF-3fs: Past - 3rd person feminine singular = הלכה\n",
      "PERF-3p: Past - 3p = הלכו\n",
      "IMPF-1s: Future - 1st person singular = אלך\n",
      "IMPF-1p: Future - 1st person plural = נלך\n",
      "IMPF-2ms: Future - 2nd person masculine singular = תלך\n",
      "IMPF-2fs: Future - 2nd person feminine singular = תלכי\n",
      "IMPF-2mp: Future - 2nd person masculine plural = תלכו\n",
      "IMPF-2fp: Future - 2nd person feminine plural = תלכנה\n",
      "IMPF-3ms: Future - 3rd person masculine singular = ילך\n",
      "IMPF-3fs: Future - 3rd person feminine singular = תלך\n",
      "IMPF-3mp: Future - 3rd person masculine plural = ילכו\n",
      "IMPF-3fp: Future - 3rd person feminine plural = תלכנה\n",
      "INF-L: Infinitive - long form = ללכת\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "for k, v in conj_dict.items():\n",
    "    parsed_key = parse_conjugation_key(k, conjugation_key_map)\n",
    "    print(f\"{k}: {parsed_key} = {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dc6c8d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP-ms: הולך\n",
      "AP-fs: הולכת\n",
      "AP-mp: הולכים\n",
      "AP-fp: הולכות\n",
      "PERF-1s: הלכתי\n",
      "PERF-1p: הלכנו\n",
      "PERF-2ms: הלכת\n",
      "PERF-2fs: הלכת\n",
      "PERF-2mp: הלכתם\n",
      "PERF-2fp: הלכתן\n",
      "PERF-3ms: הלך\n",
      "PERF-3fs: הלכה\n",
      "PERF-3p: הלכו\n",
      "IMPF-1s: אלך\n",
      "IMPF-1p: נלך\n",
      "IMPF-2ms: תלך\n",
      "IMPF-2fs: תלכי\n",
      "IMPF-2mp: תלכו\n",
      "IMPF-2fp: תלכנה\n",
      "IMPF-3ms: ילך\n",
      "IMPF-3fs: תלך\n",
      "IMPF-3mp: ילכו\n",
      "IMPF-3fp: תלכנה\n",
      "INF-L: ללכת\n"
     ]
    }
   ],
   "source": [
    "for k, v in conj_dict.items():\n",
    "    \n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
