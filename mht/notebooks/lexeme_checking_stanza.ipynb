{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5540ae5f",
   "metadata": {},
   "source": [
    "# Answer checking/sentence processing from lexemes (stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e70c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from mht.scripts.LLM_scripts.post_processing import extract_single_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57f4addd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>n_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>word_ll</th>\n",
       "      <th>word_ul</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>...</th>\n",
       "      <th>mdt_history</th>\n",
       "      <th>mdt_correct</th>\n",
       "      <th>mrt_history</th>\n",
       "      <th>mrt_correct</th>\n",
       "      <th>wdt_history</th>\n",
       "      <th>wdt_correct</th>\n",
       "      <th>wrt_history</th>\n",
       "      <th>wrt_correct</th>\n",
       "      <th>speed</th>\n",
       "      <th>rebag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_ll</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>מפלגה</th>\n",
       "      <td>0.333</td>\n",
       "      <td>201</td>\n",
       "      <td>1751016976</td>\n",
       "      <td>1043</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>מפלגה</td>\n",
       "      <td>party</td>\n",
       "      <td>מפלגה/מפלגה&lt;NOUN&gt;Fem|Sing|</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>המלצה</th>\n",
       "      <td>0.500</td>\n",
       "      <td>355</td>\n",
       "      <td>1751986534</td>\n",
       "      <td>970601</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>המלצה</td>\n",
       "      <td>recommendation</td>\n",
       "      <td>ה/ה&lt;DET&gt;Def|Art|,detמלצה/מלץ&lt;NOUN&gt;Fem|Sing|</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>איום</th>\n",
       "      <td>0.750</td>\n",
       "      <td>123</td>\n",
       "      <td>1751017555</td>\n",
       "      <td>1622</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>איום</td>\n",
       "      <td>threat</td>\n",
       "      <td>איום/איום&lt;NOUN&gt;Masc|Sing|</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>שביתה</th>\n",
       "      <td>0.800</td>\n",
       "      <td>550</td>\n",
       "      <td>1753184844</td>\n",
       "      <td>2168911</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>שביתה</td>\n",
       "      <td>strike</td>\n",
       "      <td>שביתה/שביתה&lt;NOUN&gt;Fem|Sing|</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1107</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>צלחית</th>\n",
       "      <td>1.000</td>\n",
       "      <td>234</td>\n",
       "      <td>1751015991</td>\n",
       "      <td>58</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>צלחית</td>\n",
       "      <td>saucer</td>\n",
       "      <td>צלחית/צלחית&lt;ADV&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>מעריץ</th>\n",
       "      <td>1.000</td>\n",
       "      <td>501</td>\n",
       "      <td>1751015933</td>\n",
       "      <td>0</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>מעריץ</td>\n",
       "      <td>admires</td>\n",
       "      <td>מעריץ/העריץ&lt;VERB&gt;Masc|HIFIL|Sing|1,2,3|Part|Act|</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p_recall  n_id   timestamp    delta user_id learning_language  \\\n",
       "word_ll                                                                  \n",
       "מפלגה       0.333   201  1751016976     1043   pablo                iw   \n",
       "המלצה       0.500   355  1751986534   970601   pablo                iw   \n",
       "איום        0.750   123  1751017555     1622   pablo                iw   \n",
       "שביתה       0.800   550  1753184844  2168911   pablo                iw   \n",
       "צלחית       1.000   234  1751015991       58   pablo                iw   \n",
       "מעריץ       1.000   501  1751015933        0   pablo                iw   \n",
       "\n",
       "        ui_language word_ll         word_ul  \\\n",
       "word_ll                                       \n",
       "מפלגה            en   מפלגה           party   \n",
       "המלצה            en   המלצה  recommendation   \n",
       "איום             en    איום          threat   \n",
       "שביתה            en   שביתה          strike   \n",
       "צלחית            en   צלחית          saucer   \n",
       "מעריץ            en   מעריץ         admires   \n",
       "\n",
       "                                            lexeme_string  ...  mdt_history  \\\n",
       "word_ll                                                    ...                \n",
       "מפלגה                          מפלגה/מפלגה<NOUN>Fem|Sing|  ...            0   \n",
       "המלצה         ה/ה<DET>Def|Art|,detמלצה/מלץ<NOUN>Fem|Sing|  ...            1   \n",
       "איום                            איום/איום<NOUN>Masc|Sing|  ...            0   \n",
       "שביתה                          שביתה/שביתה<NOUN>Fem|Sing|  ...            2   \n",
       "צלחית                                    צלחית/צלחית<ADV>  ...            0   \n",
       "מעריץ    מעריץ/העריץ<VERB>Masc|HIFIL|Sing|1,2,3|Part|Act|  ...            2   \n",
       "\n",
       "         mdt_correct  mrt_history  mrt_correct  wdt_history  wdt_correct  \\\n",
       "word_ll                                                                    \n",
       "מפלגה              0            1            1            0            0   \n",
       "המלצה              0            0            0            0            0   \n",
       "איום               0            2            2            1            0   \n",
       "שביתה              2            1            1            2            1   \n",
       "צלחית              0            1            1            0            0   \n",
       "מעריץ              2            1            1            0            0   \n",
       "\n",
       "         wrt_history  wrt_correct   speed  rebag  \n",
       "word_ll                                           \n",
       "מפלגה              2            0  0.1426  False  \n",
       "המלצה              1            1  0.0173  False  \n",
       "איום               1            1  0.1271  False  \n",
       "שביתה              0            0  0.1107  False  \n",
       "צלחית              1            1  0.0735  False  \n",
       "מעריץ              0            0  0.1199  False  \n",
       "\n",
       "[6 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lippath = '/Users/pabloherrero/Documents/ManHatTan/mht/data/processed/LIPSTICK/hebrew_db_team.lip'\n",
    "lip = pd.read_csv(lippath)\n",
    "lip.set_index('word_ll', inplace=True, drop=False)\n",
    "lip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d6db45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:12:38 WARNING: Language he package default expects mwt, which has been added\n",
      "2025-07-29 14:12:38 INFO: Loading these models for language: he (Hebrew):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | htb     |\n",
      "| mwt       | htb     |\n",
      "| pos       | htb     |\n",
      "| lemma     | htb     |\n",
      "| depparse  | htb     |\n",
      "=======================\n",
      "\n",
      "2025-07-29 14:12:38 INFO: Use device: cpu\n",
      "2025-07-29 14:12:38 INFO: Loading: tokenize\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/tokenization/trainer.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-07-29 14:12:38 INFO: Loading: mwt\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/mwt/trainer.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-07-29 14:12:38 INFO: Loading: pos\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/pos/trainer.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/common/pretrain.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "2025-07-29 14:12:39 INFO: Loading: lemma\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/lemma/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-07-29 14:12:39 INFO: Loading: depparse\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/depparse/trainer.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-07-29 14:12:39 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# stanza.download('he', processors='tokenize,pos,lemma,depparse')\n",
    "nlp = stanza.Pipeline('he', processors='tokenize,pos,lemma,depparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "66562f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lexeme(token, nlp=None) -> str:\n",
    "    \"\"\"    Returns a string representation of the lexeme for a given token.\n",
    "    The format is: word/lemma<upos>feat1|feat2|...deprel, where:\n",
    "    - word is the original word\n",
    "    - lemma is the lemmatized form\n",
    "    - upos is the universal part-of-speech tag\n",
    "    - feats are the morphological features, separated by '|'\n",
    "    - deprel is the dependency relation, if not 'root'\n",
    "    \"\"\"\n",
    "    if not isinstance(token, str):\n",
    "        raise ValueError(\"Input must be a string token.\")\n",
    "    if nlp is None:\n",
    "        import stanza\n",
    "        nlp = stanza.Pipeline('he', processors='tokenize,pos,lemma,depparse')\n",
    "        \n",
    "    doc = nlp(token)\n",
    "\n",
    "    for sent in doc.sentences:\n",
    "        lexeme_string = ''\n",
    "        # print(len(sent.words))\n",
    "        for word in sent.words:\n",
    "            if word.lemma:\n",
    "                lexeme_string += word.lemma \n",
    "            # if word.upos:\n",
    "            #     lexeme_string += '<' + word.upos + '>'\n",
    "            # if word.feats:\n",
    "            #     feats = word.feats.split('|')\n",
    "            #     lexeme_string += ''.join(feat.split('=')[1] +'|' for feat in feats)\n",
    "            # if word.deprel != 'root':\n",
    "            #     lexeme_string +=  ',' + word.deprel\n",
    "    return lexeme_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d60a866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexeme for מפלגות: מפלגה\n",
      "Correct lexeme\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'מפלגה/מפלגה<NOUN>Fem|Sing|'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = 'מפלגה'\n",
    "generated_word = 'מפלגות'\n",
    "lexeme_generated_word = get_lexeme(generated_word)\n",
    "print(f\"Lexeme for {generated_word}: {lexeme_generated_word}\")\n",
    "if lexeme_generated_word in lip.loc[target_word].lexeme_string:\n",
    "    print('Correct lexeme')\n",
    "lip.loc[target_word].lexeme_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38280fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexeme for מסיבות: מסיבה\n",
      "Incorrect lexeme\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'מפלגה/מפלגה<NOUN>Fem|Sing|'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = 'מפלגה'\n",
    "generated_word = 'מסיבות'\n",
    "lexeme_generated_word = get_lexeme(generated_word)\n",
    "print(f\"Lexeme for {generated_word}: {lexeme_generated_word}\")\n",
    "if lexeme_generated_word in lip.loc[target_word].lexeme_string:\n",
    "    print('Correct lexeme')\n",
    "else:\n",
    "    print('Incorrect lexeme')\n",
    "lip.loc[target_word].lexeme_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4759b053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexeme for מעריצים: מעריץ\n",
      "Correct lexeme\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'מעריץ/העריץ<VERB>Masc|HIFIL|Sing|1,2,3|Part|Act|'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = 'מעריץ'\n",
    "generated_word = 'מעריצים'\n",
    "lexeme_generated_word = get_lexeme(generated_word)\n",
    "print(f\"Lexeme for {generated_word}: {lexeme_generated_word}\")\n",
    "if lexeme_generated_word in lip.loc[target_word].lexeme_string:\n",
    "    print('Correct lexeme')\n",
    "else:\n",
    "    print('Incorrect lexeme')\n",
    "lip.loc[target_word].lexeme_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1105c54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexeme for יעריצו: העריץ\n",
      "Correct lexeme\n"
     ]
    }
   ],
   "source": [
    "target_word = 'מעריץ'\n",
    "generated_word = 'יעריצו'\n",
    "lexeme_generated_word = get_lexeme(generated_word)\n",
    "print(f\"Lexeme for {generated_word}: {lexeme_generated_word}\")\n",
    "if lexeme_generated_word in lip.loc[target_word].lexeme_string:\n",
    "    print('Correct lexeme')\n",
    "else:\n",
    "    print('Incorrect lexeme')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a7aa3",
   "metadata": {},
   "source": [
    "# Check whole generated sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "61a2c2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lexeme_contains(sentence: str, word: str, lip: pd.DataFrame, nlp = None) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Checks if the translated sentence contains the lexeme of the specified word.\n",
    "    Returns True if it does, False otherwise.\n",
    "    \"\"\"\n",
    "    target_lip_lexeme = lip.loc[word].lexeme_string\n",
    "    for word in sentence.split():\n",
    "        lexeme_word = get_lexeme(word, nlp)\n",
    "        if lexeme_word in target_lip_lexeme:\n",
    "            sentence_blank = sentence.replace(word, '_' * len(word))\n",
    "            return True, sentence_blank\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "58d80c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence contains the lexeme for 'מעריץ'.\n",
      "Blanked sentence: אנשים _______ את הזמר\n"
     ]
    }
   ],
   "source": [
    "sentence = 'אנשים מעריצים את הזמר'\n",
    "word = 'מעריץ'\n",
    "flag_contains, blank_sentence = check_lexeme_contains(sentence, word, lip, nlp=nlp)\n",
    "if flag_contains:\n",
    "    print(f\"The sentence contains the lexeme for '{word}'.\")\n",
    "    print(\"Blanked sentence:\", blank_sentence)\n",
    "else:\n",
    "    print(f\"The sentence does not contain the lexeme for '{word}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745a2b0",
   "metadata": {},
   "source": [
    "# Check in other translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de4e23ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "async def translate_sentence(sentence: str, src_lang: str = 'en', dest_lang: str = 'he') -> str:\n",
    "    \"\"\"    Translates a sentence from the source language to the destination language.\n",
    "    Uses Google Translate API asynchronously\"\"\"\n",
    "\n",
    "    print(f'Starting translation, src = {sentence}, dest_lang = {dest_lang}')\n",
    "    async with Translator() as translator:\n",
    "        \n",
    "        if not dest_lang:\n",
    "            print('No destination language specified. Using Hebrew as default.')\n",
    "            dest_lang = 'he'\n",
    "\n",
    "        translation = await translator.translate(text = sentence, dest=dest_lang, src=src_lang)\n",
    "        \n",
    "        return translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2533a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_strings(nested):\n",
    "    \"\"\"   Extracts all strings from a nested structure (list or string).\n",
    "    This function recursively traverses the structure and collects all strings.\n",
    "    \"\"\"\n",
    "    strings = []\n",
    "    if isinstance(nested, str):\n",
    "        strings.append(nested)\n",
    "    elif isinstance(nested, list):\n",
    "        for item in nested:\n",
    "            strings.extend(extract_strings(item))\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267f46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted sentence: I bought several helmets\n",
      "Starting translation, src = I bought several helmets, dest_lang = he\n",
      "Translation: Translated(src=en, dest=he, text=קניתי כמה קסדות, pronunciation=kaniti kma kasdot, extra_data=\"{'translat...\")\n",
      "['I bought several helmets', 'קניתי כמה קסדות', 'קניתי מספר קסדות', 'I bought several helmets']\n"
     ]
    }
   ],
   "source": [
    "# Example that yields two translation possibilities for \"several\"\n",
    "extracted_sentence = 'I bought several helmets'\n",
    "print(\"Extracted sentence:\", extracted_sentence)\n",
    "he_translation = await translate_sentence(extracted_sentence, src_lang='en', dest_lang='he')\n",
    "print(\"Translation:\", he_translation)\n",
    "\n",
    "possible_translations_flat = extract_strings(he_translation.extra_data['possible-translations'][0])\n",
    "print(possible_translations_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72f434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted sentence: I bought several helmets\n",
      "Starting translation, src = I bought several helmets, dest_lang = he\n",
      "Translation: Translated(src=en, dest=he, text=קניתי כמה קסדות, pronunciation=kaniti kma kasdot, extra_data=\"{'translat...\")\n",
      "['I bought several helmets', 'קניתי כמה קסדות', 'קניתי מספר קסדות', 'I bought several helmets']\n"
     ]
    }
   ],
   "source": [
    "# Example that yields two different subjects (you singular and plural)\n",
    "extracted_sentence = 'You bought several helmets'\n",
    "print(\"Extracted sentence:\", extracted_sentence)\n",
    "he_translation = await translate_sentence(extracted_sentence, src_lang='en', dest_lang='he')\n",
    "print(\"Translation:\", he_translation)\n",
    "\n",
    "possible_translations_flat = extract_strings(he_translation.extra_data['possible-translations'][0])\n",
    "print(possible_translations_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb3949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted sentence: People admire the singer\n",
      "Starting translation, src = People admire the singer, dest_lang = he\n",
      "Translation finished\n",
      "Translation: Translated(src=en, dest=he, text=אנשים מעריצים את הזמר, pronunciation=anshim ma'aritzim et hazmar, extra_data=\"{'translat...\")\n",
      "['People admire the singer', 'אנשים מעריצים את הזמר', 'אנשים מעריצים את הזמרת', 'People admire the singer']\n"
     ]
    }
   ],
   "source": [
    "# Translate sentence with two possible translations for \"singer\" (masculine and feminine)\n",
    "extracted_sentence = 'People admire the singer'\n",
    "print(\"Extracted sentence:\", extracted_sentence)\n",
    "he_translation = await translate_sentence(extracted_sentence, src_lang='en', dest_lang='he')\n",
    "print(\"Translation:\", he_translation)\n",
    "\n",
    "possible_translations_flat = extract_strings(he_translation.extra_data['possible-translations'][0])\n",
    "print(possible_translations_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e5adfc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted sentence: What do you mean by \"fair\"?\n",
      "Starting translation, src = What do you mean by \"fair\"?, dest_lang = he\n",
      "Translation: Translated(src=en, dest=he, text=למה אתה מתכוון ב\"הוגן \"?, pronunciation=lema ata mitkavan be\"hugan \"?, extra_data=\"{'translat...\")\n",
      "['What do you mean by \"fair\"?', 'למה אתה מתכוון ב\"הוגן \"?', 'למה אתה מתכוון ב\"היריד \"?', 'What do you mean by \"fair\"?']\n"
     ]
    }
   ],
   "source": [
    "# Translate sentence with several possible translations\n",
    "extracted_sentence = 'What do you mean by \"fair\"?'\n",
    "print(\"Extracted sentence:\", extracted_sentence)\n",
    "he_translation = await translate_sentence(extracted_sentence, src_lang='en', dest_lang='he')\n",
    "print(\"Translation:\", he_translation)\n",
    "\n",
    "possible_translations_flat = extract_strings(he_translation.extra_data['possible-translations'][0])\n",
    "print(possible_translations_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_other_translations(he_translation, word_ll, lip, nlp=None):\n",
    "    \"\"\"\n",
    "    Checks if the translation contains other possible translations for the word.\n",
    "    Returns a list of possible translations if found, otherwise an empty list.\n",
    "    \"\"\"\n",
    "    if not he_translation.extra_data or 'possible-translations' not in he_translation.extra_data:\n",
    "        return False\n",
    "    possible_tranlations = he_translation.extra_data['possible-translations'][0]\n",
    "    possible_translations_flat = extract_strings(possible_tranlations)\n",
    "    if not possible_translations_flat:\n",
    "        return False\n",
    "    \n",
    "    # Iterate through the possible translations and check if any of them contain the lexeme of the word\n",
    "    for possibility in possible_translations_flat:\n",
    "        # For each sentence use check_lexeme_contains to iterate through the words\n",
    "        if check_lexeme_contains(possibility, word_ll, lip, nlp):\n",
    "            return True, possibility\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_check_other_translations():\n",
    "    \"\"\"\n",
    "    Test the check_other_translations function with various inputs.\n",
    "    \"\"\"\n",
    "    # Example translation with possible translations\n",
    "    he_translation = {\n",
    "        'extra_data': {\n",
    "            'possible-translations': [\n",
    "                ['אני קניתי כמה קסדות', 'אתה קנית כמה קסדות']\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    word_ll = 'קסדה'\n",
    "    lip = pd.DataFrame({\n",
    "        'word_ll': ['קסדה'],\n",
    "        'lexeme_string': ['קסדה/קסדה<NOUN>Number=Sing|Gender=Fem']\n",
    "    }).set_index('word_ll')\n",
    "    \n",
    "    assert check_other_translations(he_translation, word_ll, lip) == True\n",
    "\n",
    "    # Example translation with possible translations that do not match the lexeme\n",
    "    he_translation = {\n",
    "        'extra_data': {\n",
    "            'possible-translations': [\n",
    "                ['אני קניתי כמה מכנסיים', 'אתה קנית כמה מכנסיים']\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    word_ll = 'קסדה'\n",
    "    lip = pd.DataFrame({\n",
    "        'word_ll': ['קסדה'],\n",
    "        'lexeme_string': ['קסדה/קסדה<NOUN>Number=Sing|Gender=Fem']\n",
    "    }).set_index('word_ll')\n",
    "\n",
    "    assert check_other_translations(he_translation, word_ll, lip) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dfd6b2",
   "metadata": {},
   "source": [
    "# Return blank instead of word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8d692d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_direct_contains(sentence, word: str) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if the translated sentence contains the specified word.\n",
    "    Returns True if it does, False otherwise.\n",
    "    \"\"\"\n",
    "    if word.lower() in sentence.text.lower():\n",
    "        sentence_blank = sentence.text.replace(word, '_' * len(word)) #'_' * len(word))\n",
    "        return True, sentence_blank\n",
    "    else: \n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214b867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'אני אוהב את ה______')\n"
     ]
    }
   ],
   "source": [
    "def test_check_direct_contains():\n",
    "    \"\"\"\n",
    "    Test the check_direct_contains function with various inputs.\n",
    "    \"\"\"\n",
    "    # Example sentence that contains the word\n",
    "    class Sentence:\n",
    "        def __init__(self, text):\n",
    "            self.text = text\n",
    "    sentence = Sentence(\"אני אוהב את התפוזים של הקיץ\")\n",
    "    word = \"תפוזים\"\n",
    "    assert check_direct_contains(sentence, word) == (True, \"אני אוהב את ה______ של הקיץ\")\n",
    "\n",
    "\n",
    "    # Example sentence that does not contain the word\n",
    "    sentence = Sentence(\"אני אוהב את התפוחים\")\n",
    "    word = \"תפוזים\"\n",
    "    assert check_direct_contains(sentence, word) == (False, None)\n",
    "\n",
    "    # Example sentence where the word is present at the end of the sentence (weird ___ positioning)\n",
    "    sentence = Sentence(\"אני אוהב את התפוזים\")\n",
    "    word = \"תפוזים\"\n",
    "    print(check_direct_contains(sentence, word))\n",
    "    assert check_direct_contains(sentence, word) == (True, \"אני אוהב את ה______\")\n",
    "\n",
    "# Run the tests\n",
    "test_check_direct_contains()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0cce1",
   "metadata": {},
   "source": [
    "# Extract random entry form lip_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3c175ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>n_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>word_ll</th>\n",
       "      <th>word_ul</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>...</th>\n",
       "      <th>mdt_history</th>\n",
       "      <th>mdt_correct</th>\n",
       "      <th>mrt_history</th>\n",
       "      <th>mrt_correct</th>\n",
       "      <th>wdt_history</th>\n",
       "      <th>wdt_correct</th>\n",
       "      <th>wrt_history</th>\n",
       "      <th>wrt_correct</th>\n",
       "      <th>speed</th>\n",
       "      <th>rebag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_ll</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>שביתה</th>\n",
       "      <td>0.8</td>\n",
       "      <td>550</td>\n",
       "      <td>1753184844</td>\n",
       "      <td>2168911</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>שביתה</td>\n",
       "      <td>strike</td>\n",
       "      <td>שביתה/שביתה&lt;NOUN&gt;Fem|Sing|</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1107</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p_recall  n_id   timestamp    delta user_id learning_language  \\\n",
       "word_ll                                                                  \n",
       "שביתה         0.8   550  1753184844  2168911   pablo                iw   \n",
       "\n",
       "        ui_language word_ll word_ul               lexeme_string  ...  \\\n",
       "word_ll                                                          ...   \n",
       "שביתה            en   שביתה  strike  שביתה/שביתה<NOUN>Fem|Sing|  ...   \n",
       "\n",
       "         mdt_history  mdt_correct  mrt_history  mrt_correct  wdt_history  \\\n",
       "word_ll                                                                    \n",
       "שביתה              2            2            1            1            2   \n",
       "\n",
       "         wdt_correct  wrt_history  wrt_correct   speed  rebag  \n",
       "word_ll                                                        \n",
       "שביתה              1            0            0  0.1107  False  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "lip.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86808a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
