{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b3f0a4",
   "metadata": {},
   "source": [
    "# Sandbook Notebook for (new) async version of googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "08d30e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab8d77",
   "metadata": {},
   "source": [
    "## Basic translation and language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b64329",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def translate_text(text, dest_language='en'):\n",
    "    async with Translator() as translator:\n",
    "        try:\n",
    "            # Perform the translation\n",
    "            translated = await translator.translate(text, dest=dest_language)\n",
    "            return translated.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error during translation: {e}\")\n",
    "            return None\n",
    "\n",
    "async def detect_language(text):\n",
    "    async with Translator() as translator:\n",
    "        try:\n",
    "            # Detect the language of the text\n",
    "            detected = await translator.detect(text)\n",
    "            return detected.lang\n",
    "        except Exception as e:\n",
    "            print(f\"Error during language detection: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59014b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Peace of the world'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await translate_text(\"שלום עולם\", dest_language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e5723a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iw'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await detect_language(\"שלום עולם\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2be6a",
   "metadata": {},
   "source": [
    "## Same for lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f65694",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def detect_language_list(texts):\n",
    "    async with Translator() as translator:\n",
    "        try:\n",
    "            # Detect the languages of a list of texts\n",
    "            detected = await translator.detect(texts)\n",
    "            return detected\n",
    "        except Exception as e:\n",
    "            print(f\"Error during language detection: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c58270e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ungeziefer', 'Versteifungen', 'Umfang']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_cder = '/Users/pabloherrero/Documents/ManHatTan/mht/data/processed/CADERAs/Die_Verwandlung.cder'\n",
    "cder = pd.read_csv(path_cder)\n",
    "word_list = list(cder['blue'].values)\n",
    "word_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b362e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f8cfe6",
   "metadata": {},
   "source": [
    "# Dev: detect most likely language from a random sample of 10 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f64d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION: running this on a large list can be slow and may hit API limits.\n",
    "# result = await detect_language_list(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e907b95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "detected_language\n",
       "de    100\n",
       "en      8\n",
       "lb      1\n",
       "hu      1\n",
       "nl      1\n",
       "sv      1\n",
       "fr      1\n",
       "sk      1\n",
       "la      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_languages = [res.lang for res in result]\n",
    "detected_confidence = [res.confidence for res in result]\n",
    "detection_stats = pd.DataFrame({\n",
    "    'detected_language': detected_languages,\n",
    "    'confidence': detected_confidence\n",
    "})\n",
    "detection_stats['detected_language'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52f63d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detected_language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0.936481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0.722688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>0.599222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl</th>\n",
       "      <td>0.502095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lb</th>\n",
       "      <td>0.458477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk</th>\n",
       "      <td>0.281745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hu</th>\n",
       "      <td>0.176923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   confidence\n",
       "detected_language            \n",
       "la                   1.000000\n",
       "de                   0.936481\n",
       "en                   0.722688\n",
       "sv                   0.599222\n",
       "fr                   0.570312\n",
       "nl                   0.502095\n",
       "lb                   0.458477\n",
       "sk                   0.281745\n",
       "hu                   0.176923"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_stats.groupby('detected_language').mean().sort_values(by='confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f57ce3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detected_language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>93.648051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>5.781500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>0.599222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl</th>\n",
       "      <td>0.502095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lb</th>\n",
       "      <td>0.458477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk</th>\n",
       "      <td>0.281745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hu</th>\n",
       "      <td>0.176923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   confidence\n",
       "detected_language            \n",
       "de                  93.648051\n",
       "en                   5.781500\n",
       "la                   1.000000\n",
       "sv                   0.599222\n",
       "fr                   0.570312\n",
       "nl                   0.502095\n",
       "lb                   0.458477\n",
       "sk                   0.281745\n",
       "hu                   0.176923"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_stats.groupby('detected_language').sum().sort_values(by='confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef166d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_sample = detection_stats.sample(10)\n",
    "grouped_confidences = stat_sample.groupby('detected_language').sum().sort_values(by='confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f29ec954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_confidence = grouped_confidences[grouped_confidences['confidence'] == grouped_confidences['confidence'].max()]\n",
    "predicted_lang, summed_conf = max_confidence.index[0], max_confidence['confidence'].values[0]\n",
    "min_confidence = 4.0\n",
    "summed_conf > min_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca11803",
   "metadata": {},
   "source": [
    "### Write function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cdf0353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def find_language(word_list: list, min_confidence=4.0):\n",
    "    \"\"\"Detect language of the blue column in CADERA.\n",
    "    Parameters:\n",
    "    word_list : list\n",
    "        List of words to sample for language detection. Should be at least 10 words long.\n",
    "    min_confidence : float\n",
    "        Minimum confidence threshold for language detection. Default is 4.0.\n",
    "    Returns:\n",
    "    str or None\n",
    "        Detected language code if confidence is above the threshold, otherwise None.\n",
    "    Usage:\n",
    "    >>> cder = pd.read_csv('path_to_cadera.cder')\n",
    "    >>> detected_lang = await find_language(cder, min_confidence=4.0)\n",
    "    >>> print(detected_lang)  # Outputs the detected language code or None if confidence is low\n",
    "    \"\"\"\n",
    "\n",
    "    if not word_list or len(word_list) < 10:\n",
    "        print(\"The word list too short. Cannot detect language confidently.\")\n",
    "        return None\n",
    "    # Sample 10 words from the word_list\n",
    "\n",
    "    sample_list = random.sample(word_list, 10)\n",
    "\n",
    "    result = await detect_language_list(sample_list)\n",
    "    \n",
    "    detected_languages = [res.lang for res in result]\n",
    "    detected_confidence = [res.confidence for res in result]\n",
    "    \n",
    "    detection_stats = pd.DataFrame({\n",
    "        'detected_language': detected_languages,\n",
    "        'confidence': detected_confidence\n",
    "    })\n",
    "    \n",
    "    grouped_confidences = detection_stats.groupby('detected_language').sum().sort_values(by='confidence', ascending=False)\n",
    "    \n",
    "    max_confidence = grouped_confidences[grouped_confidences['confidence'] == grouped_confidences['confidence'].max()]\n",
    "    predicted_lang, summed_conf = max_confidence.index[0], max_confidence['confidence'].values[0]\n",
    "    \n",
    "    if summed_conf < min_confidence:\n",
    "        print(f\"Predicted language '{predicted_lang}' with confidence {summed_conf/10} is below the minimum threshold of {min_confidence/10}.\")\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"Predicted language: {predicted_lang} with confidence: {summed_conf/10}\")\n",
    "        return predicted_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6306c8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordll_list = cder['blue'].dropna().to_list()\n",
    "len(wordll_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fc9ceadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted language: de with confidence: 0.69423519\n"
     ]
    }
   ],
   "source": [
    "src_lang = await find_language(wordll_list, min_confidence=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eff48eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['verraten.',\n",
       " 'Heidengeld',\n",
       " 'bisweilen',\n",
       " 'wehren',\n",
       " 'üppigen',\n",
       " 'Pult',\n",
       " 'Munterkeit',\n",
       " 'Plafond',\n",
       " 'Klinke,',\n",
       " 'erstarrte']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(wordll_list, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29d00f",
   "metadata": {},
   "source": [
    "# Debug bulkTranslate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b965bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_src(src_list : list) -> list:\n",
    "    \"\"\"Remove non-alphanumeric characters from source array\n",
    "        Parameters\n",
    "        src_list : list\n",
    "            Source series to be formatted\n",
    "        Returns\n",
    "        src_formatted : list\n",
    "            Formatted source series\n",
    "    \"\"\"\n",
    "    \n",
    "    src_formatted = [re.sub(pattern = '[\\W_](?<![\\n\\s])', repl='', string=w) for w in src_list]   # Remove tabs\n",
    "    src_formatted = [re.sub(r'[,.;:\"]', '', w) for w in src_formatted]    #Remove ortographic symbols\n",
    "\n",
    "    return src_formatted\n",
    "\n",
    "async def bulk_translate(src_list: list, src_lang: str, dest_lang: str = None):\n",
    "    \"\"\"Translate a list of strings from src_lang to dest_lang using googletrans.\n",
    "    Parameters:\n",
    "    src_list : list\n",
    "        List of strings to be translated.\n",
    "    src_lang : str\n",
    "        Source language code (e.g., 'en', 'de', 'es').\n",
    "    dest_lang : str, optional\n",
    "        Destination language code (e.g., 'en', 'de', 'es'). If not specified, defaults to 'en'.\n",
    "    Returns:\n",
    "    dest_list : list\n",
    "        List of translated strings in the destination language.\n",
    "    Usage:\n",
    "    >>> translated_df = await bulk_translate(['Hello', 'World'], 'en', 'es')\n",
    "    \"\"\"\n",
    "\n",
    "    async with Translator() as translator:\n",
    "        print(f'Starting translation, src = {src_list}, dest_lang = {dest_lang}')\n",
    "        \n",
    "        if not dest_lang:\n",
    "            print('No destination language specified. Using English as default.')\n",
    "            dest_lang = 'en'\n",
    "\n",
    "        dest_list = await translator.translate(text = src_list, dest=dest_lang, src=src_lang)\n",
    "        print('Translation finished')\n",
    "        \n",
    "        return dest_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c6fd8993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ungeziefer',\n",
       " 'Versteifungen',\n",
       " 'Umfang',\n",
       " 'flimmerten',\n",
       " 'versehen',\n",
       " 'Fensterblech',\n",
       " 'undurchführbar',\n",
       " 'schaukelte',\n",
       " 'Jucken',\n",
       " 'Pult',\n",
       " 'Zeiger',\n",
       " 'Donnerwetter',\n",
       " 'Rückgrat',\n",
       " 'Einwände',\n",
       " 'arbeitsscheue',\n",
       " 'derart',\n",
       " 'ausführlich',\n",
       " 'Faust',\n",
       " 'Einbildung',\n",
       " 'Vorbote',\n",
       " 'tüchtigen',\n",
       " 'Willkür',\n",
       " 'Zuversicht',\n",
       " 'Munterkeit',\n",
       " 'Krach',\n",
       " 'endgültig',\n",
       " 'erstarrte',\n",
       " 'Versäumnis',\n",
       " 'Lumpen',\n",
       " 'Angelegenheit',\n",
       " 'verständigen',\n",
       " 'gnädige',\n",
       " 'schluchzen',\n",
       " 'Ungewißheit',\n",
       " 'Rändern',\n",
       " 'verständigten',\n",
       " 'Zuversicht',\n",
       " 'Kiefer',\n",
       " 'Aufmunterung',\n",
       " 'Klinke',\n",
       " 'plump',\n",
       " 'feindseligem',\n",
       " 'überreicher',\n",
       " 'Heidengeld',\n",
       " 'beirren',\n",
       " 'wehren',\n",
       " 'gefährdet',\n",
       " 'gefaßt',\n",
       " 'Zischlaute',\n",
       " 'Abenddämmerung',\n",
       " 'ohnmachtähnlichen',\n",
       " 'Narbe',\n",
       " 'hinken',\n",
       " 'Napf',\n",
       " 'heiklen',\n",
       " 'Unannehmlichkeiten',\n",
       " 'nachdrücklich',\n",
       " 'verzehrte',\n",
       " 'tüchtig',\n",
       " 'verraten',\n",
       " 'allmählich',\n",
       " 'scheute',\n",
       " 'zitterte',\n",
       " 'Vernunftgründen',\n",
       " 'billigte',\n",
       " 'Plafond',\n",
       " 'Aufenthalt',\n",
       " 'ererbten',\n",
       " 'Einwirkungen',\n",
       " 'entbehren',\n",
       " 'Trotz',\n",
       " 'Entschlusse',\n",
       " 'unweigerlich',\n",
       " 'Ohnmacht',\n",
       " 'ätzende',\n",
       " 'besänftigen',\n",
       " 'wütend',\n",
       " 'ausgerückt',\n",
       " 'Krückstock',\n",
       " 'zerzauste',\n",
       " 'Scheitelfrisur',\n",
       " 'verbissenem',\n",
       " 'Sehkraft',\n",
       " 'Schonung',\n",
       " 'weigerte',\n",
       " 'Infolgedessen',\n",
       " 'Eigensinn',\n",
       " 'Ärmel',\n",
       " 'Achseln',\n",
       " 'erzielten',\n",
       " 'anstarrten',\n",
       " 'Hausknecht',\n",
       " 'unzugänglich',\n",
       " 'gebührte',\n",
       " 'Knäuel',\n",
       " 'vorbehalten',\n",
       " 'Schluchzen',\n",
       " 'überdrüssig',\n",
       " 'Abscheu',\n",
       " 'söhnte',\n",
       " 'Zimmerherren',\n",
       " 'rührte',\n",
       " 'mannigfachen',\n",
       " 'Gleichgültigkeit',\n",
       " 'Und trotz dieses Zustandes hatte er keine Scheu ein Stück auf dem makellosen Fußboden des Wohnzimmers vorzurücken',\n",
       " 'Polster',\n",
       " '30',\n",
       " 'Ratlosigkeit',\n",
       " 'Andenken',\n",
       " 'Benehmen',\n",
       " 'behaglich',\n",
       " 'krepiert',\n",
       " 'mürrisch',\n",
       " 'bisweilen',\n",
       " 'üppigen']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_str = [re.sub(pattern = '[\\W_](?<![\\n\\s])', repl='', string=w) for w in word_list]   # Remove tabs\n",
    "src_str = [re.sub(r'[,.;:\"]', '', w) for w in src_str]    #Remove ortographic symbols\n",
    "src_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7617c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting translation, src = ['Ungeziefer', 'Versteifungen', 'Umfang', 'flimmerten', 'versehen,', 'Fensterblech', 'undurchführbar,', 'schaukelte', 'Jucken', 'Pult', 'Zeiger', 'Donnerwetter', 'Rückgrat', 'Einwände', 'arbeitsscheue', 'derart', 'ausführlich', 'Faust.', 'Einbildung', 'Vorbote', 'tüchtigen', 'Willkür', 'Zuversicht', 'Munterkeit', 'Krach,', 'endgültig', 'erstarrte', 'Versäumnis', 'Lumpen,', 'Angelegenheit', 'verständigen:', 'gnädige', 'schluchzen.', 'Ungewißheit,', 'Rändern', 'verständigten', 'Zuversicht', 'Kiefer', 'Aufmunterung;', 'Klinke,', 'plump', 'feindseligem', 'überreicher', 'Heidengeld', 'beirren', 'wehren', 'gefährdet', 'gefaßt', 'Zischlaute', 'Abenddämmerung', 'ohnmachtähnlichen', 'Narbe,', 'hinken.', 'Napf', 'heiklen', 'Unannehmlichkeiten', 'nachdrücklich', 'verzehrte', 'tüchtig', 'verraten.', 'allmählich', 'scheute', 'zitterte', 'Vernunftgründen', 'billigte.', 'Plafond', 'Aufenthalt', 'ererbten', 'Einwirkungen', 'entbehren;', 'Trotz', 'Entschlusse', 'unweigerlich', 'Ohnmacht', 'ätzende', 'besänftigen', 'wütend', 'ausgerückt', 'Krückstock', 'zerzauste', 'Scheitelfrisur', 'verbissenem', 'Sehkraft', 'Schonung', 'weigerte', 'Infolgedessen', 'Eigensinn,', 'Ärmel,', 'Achseln', 'erzielten', 'anstarrten.', 'Hausknecht,', 'unzugänglich,', 'gebührte.', 'Knäuel', 'vorbehalten', 'Schluchzen', 'überdrüssig', 'Abscheu', 'söhnte', 'Zimmerherren', 'rührte.', 'mannigfachen', 'Gleichgültigkeit', 'Und trotz dieses Zustandes hatte er keine Scheu, ein Stück auf dem makellosen Fußboden des Wohnzimmers vorzurücken.', 'Polster', '30', 'Ratlosigkeit,', 'Andenken', 'Benehmen', 'behaglich.', 'krepiert;', 'mürrisch', 'bisweilen', 'üppigen'], dest_lang = en\n",
      "Translation finished\n"
     ]
    }
   ],
   "source": [
    "dest_lang = 'en'\n",
    "# src_lang = await find_language(wordll_list, min_confidence=4.0)\n",
    "dest_list = await bulk_translate(wordll_list , src_lang, dest_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eb56ab0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vermin', 'de', None)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_list[0].text, dest_list[0].src, dest_list[0].pronunciation,# dest_list[0].extra_data, dest_list[0].origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1810bbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ungeziefer</td>\n",
       "      <td>vermin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Versteifungen</td>\n",
       "      <td>Stiffeners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umfang</td>\n",
       "      <td>Scope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flimmerten</td>\n",
       "      <td>flicker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>versehen,</td>\n",
       "      <td>provided,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>behaglich.</td>\n",
       "      <td>cozy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>krepiert;</td>\n",
       "      <td>crepo;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>mürrisch</td>\n",
       "      <td>grumpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>bisweilen</td>\n",
       "      <td>sometimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>üppigen</td>\n",
       "      <td>lush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                de          en\n",
       "0       Ungeziefer      vermin\n",
       "1    Versteifungen  Stiffeners\n",
       "2           Umfang       Scope\n",
       "3       flimmerten     flicker\n",
       "4        versehen,   provided,\n",
       "..             ...         ...\n",
       "109     behaglich.       cozy.\n",
       "110      krepiert;      crepo;\n",
       "111       mürrisch      grumpy\n",
       "112      bisweilen   sometimes\n",
       "113        üppigen        lush\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_text_list = [d.text for d in dest_list]\n",
    "assert len(dest_text_list) == len(wordll_list), 'bulk_translate error: len(dest) does not match len(src)'\n",
    "\n",
    "dest_dict = {}\n",
    "for s, d in zip(wordll_list, dest_list):\n",
    "    dest_dict[s] = d.text\n",
    "gota_df = pd.DataFrame(dest_dict.items(), columns=[src_lang, dest_lang])\n",
    "gota_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3d1ca146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>creation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ungeziefer</td>\n",
       "      <td>vermin</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Versteifungen</td>\n",
       "      <td>Stiffeners</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umfang</td>\n",
       "      <td>Scope</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flimmerten</td>\n",
       "      <td>flicker</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>versehen,</td>\n",
       "      <td>provided,</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>behaglich.</td>\n",
       "      <td>cozy.</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>krepiert;</td>\n",
       "      <td>crepo;</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>mürrisch</td>\n",
       "      <td>grumpy</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>bisweilen</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>üppigen</td>\n",
       "      <td>lush</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                de          en  creation_time\n",
       "0       Ungeziefer      vermin     1751101789\n",
       "1    Versteifungen  Stiffeners     1751101789\n",
       "2           Umfang       Scope     1751101789\n",
       "3       flimmerten     flicker     1751101789\n",
       "4        versehen,   provided,     1751101789\n",
       "..             ...         ...            ...\n",
       "109     behaglich.       cozy.     1751101789\n",
       "110      krepiert;      crepo;     1751101789\n",
       "111       mürrisch      grumpy     1751101789\n",
       "112      bisweilen   sometimes     1751101789\n",
       "113        üppigen        lush     1751101789\n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_gota_df(wordll_list, dest_list, path_cder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a4a7d",
   "metadata": {},
   "source": [
    "### Check if GOTA exists in bulkTranslate_main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "980ecd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_words_selected_color(cadera_path : str, src_lang : str, word_color: str = 'blue') -> list:\n",
    "    \"\"\"Load column with selected from CADERA as list\"\"\"\n",
    "    df = pd.read_csv(cadera_path, index_col=0)\n",
    "    src_list = df[word_color].dropna().to_list()  # Load blue column as list\n",
    "\n",
    "    return src_list\n",
    "\n",
    "def check_language(lang : str, meta_lang : str):\n",
    "    \"\"\"Check whether given dest and src languages are valid\"\"\"\n",
    "\n",
    "    from googletrans import LANGUAGES\n",
    "    langKeys = list(LANGUAGES.keys())\n",
    "\n",
    "    if lang not in langKeys:\n",
    "        print('Invalid %s language. Choose from one of the following keys' %meta_lang)\n",
    "        print(langKeys)\n",
    "        exit\n",
    "\n",
    "def get_gota_path(cadera_path : str) -> str:\n",
    "    \"\"\"Take basename from cadera and make GOTA path\"\"\"\n",
    "    pathname = os.path.splitext(os.path.abspath(cadera_path))[0]\n",
    "    path, filename = os.path.split(pathname)\n",
    "    dirPath, _ = os.path.split(path)\n",
    "    gota_path = os.path.join(dirPath, 'GOTAs', filename+'.got')\n",
    "    if not os.path.exists(os.path.dirname(gota_path)):\n",
    "        os.makedirs(os.path.dirname(gota_path))\n",
    "    return gota_path\n",
    "\n",
    "def write_gota(gota_df : pd.DataFrame, gota_path : str):\n",
    "    \"\"\"Write GOTA DataFrame to file\"\"\"\n",
    "\n",
    "    gota_df.to_csv(gota_path, index=False)\n",
    "    print('Created GOTA file %s' %gota_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d89528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_new_elements(src_list: list, src_lang: str, gota_df: pd.DataFrame) -> list:\n",
    "    \"\"\"Check for new elements in the source string that are not in the GOTA DataFrame.\"\"\"\n",
    "    \n",
    "    mask = pd.Series(src_list).isin(gota_df[src_lang])\n",
    "    new_words = [w for w in src_list if w not in set(gota_df[src_lang])]\n",
    "\n",
    "    if not new_words:\n",
    "        print('No new elements to translate.')\n",
    "        return None\n",
    "    else:\n",
    "        print(f'New elements to translate: {len(new_words)}')\n",
    "        return new_words\n",
    "\n",
    "def make_gota_df(src_list : list, dest_list : list, src_lang: str, dest_lang: str, cadera_path : str) -> pd.DataFrame:\n",
    "    \"\"\"Assemble src and dest lists into gota_df (GOgle Translation Archive)\n",
    "    and append first creation datetime (read_time)\"\"\"\n",
    "    dest_text_list = [d.text for d in dest_list]\n",
    "\n",
    "    assert len(src_list) == len(dest_text_list), 'bulk_translate error: len(dest) does not match len(src)'\n",
    "\n",
    "    dest_dict = {}\n",
    "    for s, d in zip(src_list, dest_list):\n",
    "        dest_dict[s] = d.text\n",
    "    gota_df = pd.DataFrame(dest_dict.items(), columns=[src_lang, dest_lang])\n",
    "    \n",
    "    gota_df.name = os.path.splitext(os.path.basename(cadera_path))[0]\n",
    "    #today = datetime.datetime.today()\n",
    "    today = int(datetime.datetime.timestamp(datetime.datetime.today())) # Correct in init_lipstick.py\n",
    "\n",
    "    gota_df['creation_time'] = today\n",
    "    return gota_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226edbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def bulkTranslate_main(cadera_path : str, word_color: str, dest_lang : str, src_lang : str):\n",
    "    \"\"\"Main function to handle bulk translation from CADERA file\n",
    "        Parameters:\n",
    "        cadera_path : str\n",
    "            Path to the CADERA file.\n",
    "        word_color : str\n",
    "            Color of the words to be translated (e.g., 'blue').\n",
    "        dest_lang : str\n",
    "            Destination language code (e.g., 'en', 'de', 'es').\n",
    "        src_lang : str\n",
    "            Source language code (e.g., 'en', 'de', 'es').\n",
    "        Returns:\n",
    "        gota_path : str\n",
    "            Path to the GOTA file created after translation.\"\"\"\n",
    "    \n",
    "    check_language(dest_lang, 'dest')\n",
    "    check_language(src_lang, 'src')\n",
    "    print('Correct language format')\n",
    "\n",
    "    src_unformat = load_words_selected_color(cadera_path, src_lang, word_color)\n",
    "    src_list = format_src(src_unformat)    # Remove non-alphanumeric characters\n",
    "\n",
    "    gota_path = get_gota_path(cadera_path)\n",
    "    if os.path.exists(gota_path):\n",
    "        print('GOTA file already exists, overwriting...')\n",
    "        current_gota_df = pd.read_csv(gota_path)\n",
    "        src_list = check_new_elements(src_list, src_lang, current_gota_df)  # Keep only new elements\n",
    "        if src_list is None:\n",
    "            print('No new elements to translate. Finished translating...')\n",
    "            return gota_path\n",
    "    else:\n",
    "        current_gota_df = None\n",
    "        print('Creating new GOTA file...')\n",
    "        \n",
    "    dest_list = await bulk_translate(src_list, src_lang, dest_lang)\n",
    "\n",
    "    gota_df = make_gota_df(src_list, dest_list, src_lang=src_lang, dest_lang=dest_lang, cadera_path= cadera_path)\n",
    "    \n",
    "    if current_gota_df is not None:   # If GOTA file already exists, append new data\n",
    "        print('Appending new data to existing GOTA file...')\n",
    "        gota_df = pd.concat([current_gota_df, gota_df], ignore_index=True)\n",
    "    gota_path = write_gota(gota_df, gota_path)\n",
    "    print('GOTA file written to %s' %gota_path)\n",
    "    return gota_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f46343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOTA file already exists, overwriting...\n",
      "No new elements to translate.\n"
     ]
    }
   ],
   "source": [
    "path_cder = '/Users/pabloherrero/Documents/ManHatTan/mht/data/processed/CADERAs/Die_Verwandlung.cder'\n",
    "path_gota = get_gota_path(path_cder)\n",
    "\n",
    "if os.path.exists(path_gota):\n",
    "    print('GOTA file already exists, overwriting...')\n",
    "    current_gota_df = pd.read_csv(path_gota)\n",
    "    src_list = check_new_elements(src_str, src_lang, current_gota_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdf76e",
   "metadata": {},
   "source": [
    "# Integrate GOST pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "cb4658b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lang_dic(languages: list):\n",
    "    \"\"\"Return a dict with inverted langcodes\n",
    "    Ex: {'en': 'English'\n",
    "        'eu': 'Basque'}\n",
    "    Takes a list with long languages names ('English', 'Basque')\n",
    "    \"\"\"\n",
    "    from googletrans import LANGCODES as dictTrans\n",
    "\n",
    "    lang_dict = {}\n",
    "    for lang in languages:\n",
    "        try:\n",
    "            lang_key = dictTrans[lang.lower()]\n",
    "            lang_dict[lang] = lang_key\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return lang_dict\n",
    "\n",
    "def gost2gota(gost: pd.DataFrame, langs: dict, ll: str, ul:str):\n",
    "    \"\"\"Adapt GOST to GOTA format for LIPSTICK processing\n",
    "    Parameters:\n",
    "        ll: learning language in short format\n",
    "        ul: user language in short format ('en', 'de', 'es'...)\n",
    "    \"\"\"\n",
    "    lll, lul = langs[ll], langs[ul]             # Long-format Learning Language // Long-format User Language\n",
    "    # Group and rearrange the words by language\n",
    "    gota = pd.DataFrame({ll:[], ul: []})\n",
    "    gota[ll] = gost.apply(lambda x: x[\"source_word\"] if x[\"source_lang\"] == lll else x[\"translation\"], axis=1 )\n",
    "    gota[ul] = gost.apply(lambda x: x[\"source_word\"] if x[\"source_lang\"] == lul else x[\"translation\"], axis=1 )\n",
    "\n",
    "    # Add creation timestamp\n",
    "    today = int(datetime.datetime.timestamp(datetime.datetime.today()))\n",
    "    gota['creation_time'] = today\n",
    "    return gota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gost_main(gost_path: str, ll: str, ul:str):\n",
    "\n",
    "    gost = pd.read_csv(gost_path, names=['source_lang', 'target_lang', 'source_word', 'translation'])\n",
    "    languages = gost['source_lang'].unique()\n",
    "    if len(languages) < 2:\n",
    "        print('GOST file does not contain enough languages to process. Exiting...')\n",
    "        return None\n",
    "    print('GOST file contains the following languages:', languages)\n",
    "    if ll not in languages or ul not in languages:\n",
    "        print('Learning language (%s) or User language (%s) not found in GOST file. Exiting...' %(ll, ul))\n",
    "        return None\n",
    "    \n",
    "    langs = make_lang_dic(languages)\n",
    "    \n",
    "    gota_df = gost2gota(gost, langs, ll, ul)\n",
    "\n",
    "    if ll == 'iw':\n",
    "        gota_df = remove_nikud(gota_df)\n",
    "\n",
    "    return gota_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f71adbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Saved Translations detected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_lang</th>\n",
       "      <th>target_lang</th>\n",
       "      <th>source_word</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>creature</td>\n",
       "      <td>יְצוּר</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>monster</td>\n",
       "      <td>מִפלֶצֶת</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>servant</td>\n",
       "      <td>מְשָׁרֵת</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>magician</td>\n",
       "      <td>קוֹסֵם</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>English</td>\n",
       "      <td>גיבור</td>\n",
       "      <td>a hero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>English</td>\n",
       "      <td>צבא</td>\n",
       "      <td>Army</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>English</td>\n",
       "      <td>חמוד</td>\n",
       "      <td>Cute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>English</td>\n",
       "      <td>ביקשת</td>\n",
       "      <td>you asked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>English</td>\n",
       "      <td>להתקלח</td>\n",
       "      <td>shower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>English</td>\n",
       "      <td>חָצוּף</td>\n",
       "      <td>insolent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    source_lang target_lang source_word translation\n",
       "0       English      Hebrew    creature      יְצוּר\n",
       "1       English      Hebrew     monster    מִפלֶצֶת\n",
       "2       English      Hebrew     servant    מְשָׁרֵת\n",
       "3       English      Hebrew    magician      קוֹסֵם\n",
       "4        Hebrew     English       גיבור      a hero\n",
       "..          ...         ...         ...         ...\n",
       "288      Hebrew     English         צבא        Army\n",
       "289      Hebrew     English        חמוד        Cute\n",
       "290      Hebrew     English       ביקשת   you asked\n",
       "291      Hebrew     English      להתקלח      shower\n",
       "292      Hebrew     English      חָצוּף    insolent\n",
       "\n",
       "[293 rows x 4 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/pabloherrero/Documents/ManHatTan/mht/data/raw/googletranslate_csv/hebrew_db.csv'\n",
    "filepath, basename = os.path.split(filename)\n",
    "\n",
    "if '.csv' in basename:\n",
    "    print('Google Saved Translations detected')\n",
    "    flag_needs_processing = False\n",
    "    gost_path = filename\n",
    "    gost = pd.read_csv(gost_path, names=['source_lang', 'target_lang', 'source_word', 'translation'])\n",
    "gost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "765ac6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'English': 'en', 'Hebrew': 'iw'}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = gost['source_lang'].unique()\n",
    "langs = make_lang_dic(languages)\n",
    "langs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
