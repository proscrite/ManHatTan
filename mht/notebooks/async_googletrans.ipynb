{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b3f0a4",
   "metadata": {},
   "source": [
    "# Sandbook Notebook for (new) async version of googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "08d30e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab8d77",
   "metadata": {},
   "source": [
    "## Basic translation and language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b64329",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def translate_text(text, dest_language='en'):\n",
    "    async with Translator() as translator:\n",
    "        try:\n",
    "            # Perform the translation\n",
    "            translated = await translator.translate(text, dest=dest_language)\n",
    "            return translated.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error during translation: {e}\")\n",
    "            return None\n",
    "\n",
    "async def detect_language(text):\n",
    "    async with Translator() as translator:\n",
    "        try:\n",
    "            # Detect the language of the text\n",
    "            detected = await translator.detect(text)\n",
    "            return detected.lang\n",
    "        except Exception as e:\n",
    "            print(f\"Error during language detection: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59014b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Peace of the world'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await translate_text(\"שלום עולם\", dest_language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e5723a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iw'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await detect_language(\"שלום עולם\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2be6a",
   "metadata": {},
   "source": [
    "## Same for lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f65694",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def detect_language_list(texts):\n",
    "    async with Translator() as translator:\n",
    "        try:\n",
    "            # Detect the languages of a list of texts\n",
    "            detected = await translator.detect(texts)\n",
    "            return detected\n",
    "        except Exception as e:\n",
    "            print(f\"Error during language detection: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c58270e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ungeziefer', 'Versteifungen', 'Umfang']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_cder = '/Users/pabloherrero/Documents/ManHatTan/mht/data/processed/CADERAs/Die_Verwandlung.cder'\n",
    "cder = pd.read_csv(path_cder)\n",
    "word_list = list(cder['blue'].values)\n",
    "word_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b362e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f8cfe6",
   "metadata": {},
   "source": [
    "# Dev: detect most likely language from a random sample of 10 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f64d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION: running this on a large list can be slow and may hit API limits.\n",
    "# result = await detect_language_list(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e907b95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "detected_language\n",
       "de    100\n",
       "en      8\n",
       "lb      1\n",
       "hu      1\n",
       "nl      1\n",
       "sv      1\n",
       "fr      1\n",
       "sk      1\n",
       "la      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_languages = [res.lang for res in result]\n",
    "detected_confidence = [res.confidence for res in result]\n",
    "detection_stats = pd.DataFrame({\n",
    "    'detected_language': detected_languages,\n",
    "    'confidence': detected_confidence\n",
    "})\n",
    "detection_stats['detected_language'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52f63d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detected_language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0.936481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0.722688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>0.599222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl</th>\n",
       "      <td>0.502095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lb</th>\n",
       "      <td>0.458477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk</th>\n",
       "      <td>0.281745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hu</th>\n",
       "      <td>0.176923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   confidence\n",
       "detected_language            \n",
       "la                   1.000000\n",
       "de                   0.936481\n",
       "en                   0.722688\n",
       "sv                   0.599222\n",
       "fr                   0.570312\n",
       "nl                   0.502095\n",
       "lb                   0.458477\n",
       "sk                   0.281745\n",
       "hu                   0.176923"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_stats.groupby('detected_language').mean().sort_values(by='confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f57ce3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detected_language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>93.648051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>5.781500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>0.599222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl</th>\n",
       "      <td>0.502095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lb</th>\n",
       "      <td>0.458477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk</th>\n",
       "      <td>0.281745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hu</th>\n",
       "      <td>0.176923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   confidence\n",
       "detected_language            \n",
       "de                  93.648051\n",
       "en                   5.781500\n",
       "la                   1.000000\n",
       "sv                   0.599222\n",
       "fr                   0.570312\n",
       "nl                   0.502095\n",
       "lb                   0.458477\n",
       "sk                   0.281745\n",
       "hu                   0.176923"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_stats.groupby('detected_language').sum().sort_values(by='confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef166d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_sample = detection_stats.sample(10)\n",
    "grouped_confidences = stat_sample.groupby('detected_language').sum().sort_values(by='confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f29ec954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_confidence = grouped_confidences[grouped_confidences['confidence'] == grouped_confidences['confidence'].max()]\n",
    "predicted_lang, summed_conf = max_confidence.index[0], max_confidence['confidence'].values[0]\n",
    "min_confidence = 4.0\n",
    "summed_conf > min_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca11803",
   "metadata": {},
   "source": [
    "### Write function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cdf0353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def find_language(word_list: list, min_confidence=4.0):\n",
    "    \"\"\"Detect language of the blue column in CADERA.\n",
    "    Parameters:\n",
    "    word_list : list\n",
    "        List of words to sample for language detection. Should be at least 10 words long.\n",
    "    min_confidence : float\n",
    "        Minimum confidence threshold for language detection. Default is 4.0.\n",
    "    Returns:\n",
    "    str or None\n",
    "        Detected language code if confidence is above the threshold, otherwise None.\n",
    "    Usage:\n",
    "    >>> cder = pd.read_csv('path_to_cadera.cder')\n",
    "    >>> detected_lang = await find_language(cder, min_confidence=4.0)\n",
    "    >>> print(detected_lang)  # Outputs the detected language code or None if confidence is low\n",
    "    \"\"\"\n",
    "\n",
    "    if not word_list or len(word_list) < 10:\n",
    "        print(\"The word list too short. Cannot detect language confidently.\")\n",
    "        return None\n",
    "    # Sample 10 words from the word_list\n",
    "\n",
    "    sample_list = random.sample(word_list, 10)\n",
    "\n",
    "    result = await detect_language_list(sample_list)\n",
    "    \n",
    "    detected_languages = [res.lang for res in result]\n",
    "    detected_confidence = [res.confidence for res in result]\n",
    "    \n",
    "    detection_stats = pd.DataFrame({\n",
    "        'detected_language': detected_languages,\n",
    "        'confidence': detected_confidence\n",
    "    })\n",
    "    \n",
    "    grouped_confidences = detection_stats.groupby('detected_language').sum().sort_values(by='confidence', ascending=False)\n",
    "    \n",
    "    max_confidence = grouped_confidences[grouped_confidences['confidence'] == grouped_confidences['confidence'].max()]\n",
    "    predicted_lang, summed_conf = max_confidence.index[0], max_confidence['confidence'].values[0]\n",
    "    \n",
    "    if summed_conf < min_confidence:\n",
    "        print(f\"Predicted language '{predicted_lang}' with confidence {summed_conf/10} is below the minimum threshold of {min_confidence/10}.\")\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"Predicted language: {predicted_lang} with confidence: {summed_conf/10}\")\n",
    "        return predicted_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6306c8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordll_list = cder['blue'].dropna().to_list()\n",
    "len(wordll_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fc9ceadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted language: de with confidence: 0.69423519\n"
     ]
    }
   ],
   "source": [
    "src_lang = await find_language(wordll_list, min_confidence=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eff48eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['verraten.',\n",
       " 'Heidengeld',\n",
       " 'bisweilen',\n",
       " 'wehren',\n",
       " 'üppigen',\n",
       " 'Pult',\n",
       " 'Munterkeit',\n",
       " 'Plafond',\n",
       " 'Klinke,',\n",
       " 'erstarrte']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(wordll_list, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29d00f",
   "metadata": {},
   "source": [
    "# Debug bulkTranslate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b965bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_src(src_list : list) -> str:\n",
    "    \"\"\"Remove non-alphanumeric characters from source array\n",
    "        Parameters\n",
    "        src_list : list\n",
    "            Source series to be formatted\n",
    "        Returns\n",
    "        src_formatted : list\n",
    "            Formatted source series\n",
    "    \"\"\"\n",
    "    \n",
    "    src_formatted = [re.sub(pattern = '[\\W_](?<![\\n\\s])', repl='', string=w) for w in src_list]   # Remove tabs\n",
    "    src_formatted = [re.sub(r'[,.;:\"]', '', w) for w in src_formatted]    #Remove ortographic symbols\n",
    "\n",
    "    return src_formatted\n",
    "\n",
    "async def bulk_translate(src_list: list, src_lang: str, dest_lang: str = None):\n",
    "    \"\"\"Translate a list of strings from src_lang to dest_lang using googletrans.\n",
    "    Parameters:\n",
    "    src_list : list\n",
    "        List of strings to be translated.\n",
    "    src_lang : str\n",
    "        Source language code (e.g., 'en', 'de', 'es').\n",
    "    dest_lang : str, optional\n",
    "        Destination language code (e.g., 'en', 'de', 'es'). If not specified, defaults to 'en'.\n",
    "    Returns:\n",
    "    dest_list : list\n",
    "        List of translated strings in the destination language.\n",
    "    Usage:\n",
    "    >>> translated_df = await bulk_translate(['Hello', 'World'], 'en', 'es')\n",
    "    \"\"\"\n",
    "\n",
    "    async with Translator() as translator:\n",
    "        print(f'Starting translation, src = {src_list}, dest_lang = {dest_lang}')\n",
    "        \n",
    "        if not dest_lang:\n",
    "            print('No destination language specified. Using English as default.')\n",
    "            dest_lang = 'en'\n",
    "\n",
    "        dest_list = await translator.translate(text = src_list, dest=dest_lang, src=src_lang)\n",
    "        print('Translation finished')\n",
    "        \n",
    "        return dest_list\n",
    "\n",
    "def make_gota_df(src_list : list, dest_list : list, cadera_path : str) -> pd.DataFrame:\n",
    "    \"\"\"Assemble src and dest lists into gota_df (GOgle Translation Archive)\n",
    "    and append first creation datetime (read_time)\"\"\"\n",
    "\n",
    "    dest_dict = {}\n",
    "    for s, d in zip(src_list, dest_list):\n",
    "        dest_dict[s] = d.text\n",
    "    gota_df = pd.DataFrame(dest_dict.items(), columns=[src_lang, dest_lang])\n",
    "    \n",
    "    gota_df.name = os.path.splitext(os.path.basename(cadera_path))[0]\n",
    "    #today = datetime.datetime.today()\n",
    "    today = int(datetime.datetime.timestamp(datetime.datetime.today())) # Correct in init_lipstick.py\n",
    "\n",
    "    gota_df['creation_time'] = today\n",
    "    return gota_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c6fd8993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ungeziefer',\n",
       " 'Versteifungen',\n",
       " 'Umfang',\n",
       " 'flimmerten',\n",
       " 'versehen',\n",
       " 'Fensterblech',\n",
       " 'undurchführbar',\n",
       " 'schaukelte',\n",
       " 'Jucken',\n",
       " 'Pult',\n",
       " 'Zeiger',\n",
       " 'Donnerwetter',\n",
       " 'Rückgrat',\n",
       " 'Einwände',\n",
       " 'arbeitsscheue',\n",
       " 'derart',\n",
       " 'ausführlich',\n",
       " 'Faust',\n",
       " 'Einbildung',\n",
       " 'Vorbote',\n",
       " 'tüchtigen',\n",
       " 'Willkür',\n",
       " 'Zuversicht',\n",
       " 'Munterkeit',\n",
       " 'Krach',\n",
       " 'endgültig',\n",
       " 'erstarrte',\n",
       " 'Versäumnis',\n",
       " 'Lumpen',\n",
       " 'Angelegenheit',\n",
       " 'verständigen',\n",
       " 'gnädige',\n",
       " 'schluchzen',\n",
       " 'Ungewißheit',\n",
       " 'Rändern',\n",
       " 'verständigten',\n",
       " 'Zuversicht',\n",
       " 'Kiefer',\n",
       " 'Aufmunterung',\n",
       " 'Klinke',\n",
       " 'plump',\n",
       " 'feindseligem',\n",
       " 'überreicher',\n",
       " 'Heidengeld',\n",
       " 'beirren',\n",
       " 'wehren',\n",
       " 'gefährdet',\n",
       " 'gefaßt',\n",
       " 'Zischlaute',\n",
       " 'Abenddämmerung',\n",
       " 'ohnmachtähnlichen',\n",
       " 'Narbe',\n",
       " 'hinken',\n",
       " 'Napf',\n",
       " 'heiklen',\n",
       " 'Unannehmlichkeiten',\n",
       " 'nachdrücklich',\n",
       " 'verzehrte',\n",
       " 'tüchtig',\n",
       " 'verraten',\n",
       " 'allmählich',\n",
       " 'scheute',\n",
       " 'zitterte',\n",
       " 'Vernunftgründen',\n",
       " 'billigte',\n",
       " 'Plafond',\n",
       " 'Aufenthalt',\n",
       " 'ererbten',\n",
       " 'Einwirkungen',\n",
       " 'entbehren',\n",
       " 'Trotz',\n",
       " 'Entschlusse',\n",
       " 'unweigerlich',\n",
       " 'Ohnmacht',\n",
       " 'ätzende',\n",
       " 'besänftigen',\n",
       " 'wütend',\n",
       " 'ausgerückt',\n",
       " 'Krückstock',\n",
       " 'zerzauste',\n",
       " 'Scheitelfrisur',\n",
       " 'verbissenem',\n",
       " 'Sehkraft',\n",
       " 'Schonung',\n",
       " 'weigerte',\n",
       " 'Infolgedessen',\n",
       " 'Eigensinn',\n",
       " 'Ärmel',\n",
       " 'Achseln',\n",
       " 'erzielten',\n",
       " 'anstarrten',\n",
       " 'Hausknecht',\n",
       " 'unzugänglich',\n",
       " 'gebührte',\n",
       " 'Knäuel',\n",
       " 'vorbehalten',\n",
       " 'Schluchzen',\n",
       " 'überdrüssig',\n",
       " 'Abscheu',\n",
       " 'söhnte',\n",
       " 'Zimmerherren',\n",
       " 'rührte',\n",
       " 'mannigfachen',\n",
       " 'Gleichgültigkeit',\n",
       " 'Und trotz dieses Zustandes hatte er keine Scheu ein Stück auf dem makellosen Fußboden des Wohnzimmers vorzurücken',\n",
       " 'Polster',\n",
       " '30',\n",
       " 'Ratlosigkeit',\n",
       " 'Andenken',\n",
       " 'Benehmen',\n",
       " 'behaglich',\n",
       " 'krepiert',\n",
       " 'mürrisch',\n",
       " 'bisweilen',\n",
       " 'üppigen']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_str = [re.sub(pattern = '[\\W_](?<![\\n\\s])', repl='', string=w) for w in word_list]   # Remove tabs\n",
    "src_str = [re.sub(r'[,.;:\"]', '', w) for w in src_str]    #Remove ortographic symbols\n",
    "src_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7617c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting translation, src = ['Ungeziefer', 'Versteifungen', 'Umfang', 'flimmerten', 'versehen,', 'Fensterblech', 'undurchführbar,', 'schaukelte', 'Jucken', 'Pult', 'Zeiger', 'Donnerwetter', 'Rückgrat', 'Einwände', 'arbeitsscheue', 'derart', 'ausführlich', 'Faust.', 'Einbildung', 'Vorbote', 'tüchtigen', 'Willkür', 'Zuversicht', 'Munterkeit', 'Krach,', 'endgültig', 'erstarrte', 'Versäumnis', 'Lumpen,', 'Angelegenheit', 'verständigen:', 'gnädige', 'schluchzen.', 'Ungewißheit,', 'Rändern', 'verständigten', 'Zuversicht', 'Kiefer', 'Aufmunterung;', 'Klinke,', 'plump', 'feindseligem', 'überreicher', 'Heidengeld', 'beirren', 'wehren', 'gefährdet', 'gefaßt', 'Zischlaute', 'Abenddämmerung', 'ohnmachtähnlichen', 'Narbe,', 'hinken.', 'Napf', 'heiklen', 'Unannehmlichkeiten', 'nachdrücklich', 'verzehrte', 'tüchtig', 'verraten.', 'allmählich', 'scheute', 'zitterte', 'Vernunftgründen', 'billigte.', 'Plafond', 'Aufenthalt', 'ererbten', 'Einwirkungen', 'entbehren;', 'Trotz', 'Entschlusse', 'unweigerlich', 'Ohnmacht', 'ätzende', 'besänftigen', 'wütend', 'ausgerückt', 'Krückstock', 'zerzauste', 'Scheitelfrisur', 'verbissenem', 'Sehkraft', 'Schonung', 'weigerte', 'Infolgedessen', 'Eigensinn,', 'Ärmel,', 'Achseln', 'erzielten', 'anstarrten.', 'Hausknecht,', 'unzugänglich,', 'gebührte.', 'Knäuel', 'vorbehalten', 'Schluchzen', 'überdrüssig', 'Abscheu', 'söhnte', 'Zimmerherren', 'rührte.', 'mannigfachen', 'Gleichgültigkeit', 'Und trotz dieses Zustandes hatte er keine Scheu, ein Stück auf dem makellosen Fußboden des Wohnzimmers vorzurücken.', 'Polster', '30', 'Ratlosigkeit,', 'Andenken', 'Benehmen', 'behaglich.', 'krepiert;', 'mürrisch', 'bisweilen', 'üppigen'], dest_lang = en\n",
      "Translation finished\n"
     ]
    }
   ],
   "source": [
    "dest_lang = 'en'\n",
    "# src_lang = await find_language(wordll_list, min_confidence=4.0)\n",
    "dest_list = await bulk_translate(wordll_list , src_lang, dest_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eb56ab0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vermin', 'de', None)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_list[0].text, dest_list[0].src, dest_list[0].pronunciation,# dest_list[0].extra_data, dest_list[0].origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1810bbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ungeziefer</td>\n",
       "      <td>vermin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Versteifungen</td>\n",
       "      <td>Stiffeners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umfang</td>\n",
       "      <td>Scope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flimmerten</td>\n",
       "      <td>flicker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>versehen,</td>\n",
       "      <td>provided,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>behaglich.</td>\n",
       "      <td>cozy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>krepiert;</td>\n",
       "      <td>crepo;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>mürrisch</td>\n",
       "      <td>grumpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>bisweilen</td>\n",
       "      <td>sometimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>üppigen</td>\n",
       "      <td>lush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                de          en\n",
       "0       Ungeziefer      vermin\n",
       "1    Versteifungen  Stiffeners\n",
       "2           Umfang       Scope\n",
       "3       flimmerten     flicker\n",
       "4        versehen,   provided,\n",
       "..             ...         ...\n",
       "109     behaglich.       cozy.\n",
       "110      krepiert;      crepo;\n",
       "111       mürrisch      grumpy\n",
       "112      bisweilen   sometimes\n",
       "113        üppigen        lush\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_text_list = [d.text for d in dest_list]\n",
    "assert len(dest_text_list) == len(wordll_list), 'bulk_translate error: len(dest) does not match len(src)'\n",
    "\n",
    "dest_dict = {}\n",
    "for s, d in zip(wordll_list, dest_list):\n",
    "    dest_dict[s] = d.text\n",
    "gota_df = pd.DataFrame(dest_dict.items(), columns=[src_lang, dest_lang])\n",
    "gota_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3d1ca146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>creation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ungeziefer</td>\n",
       "      <td>vermin</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Versteifungen</td>\n",
       "      <td>Stiffeners</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umfang</td>\n",
       "      <td>Scope</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flimmerten</td>\n",
       "      <td>flicker</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>versehen,</td>\n",
       "      <td>provided,</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>behaglich.</td>\n",
       "      <td>cozy.</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>krepiert;</td>\n",
       "      <td>crepo;</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>mürrisch</td>\n",
       "      <td>grumpy</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>bisweilen</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>üppigen</td>\n",
       "      <td>lush</td>\n",
       "      <td>1751101789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                de          en  creation_time\n",
       "0       Ungeziefer      vermin     1751101789\n",
       "1    Versteifungen  Stiffeners     1751101789\n",
       "2           Umfang       Scope     1751101789\n",
       "3       flimmerten     flicker     1751101789\n",
       "4        versehen,   provided,     1751101789\n",
       "..             ...         ...            ...\n",
       "109     behaglich.       cozy.     1751101789\n",
       "110      krepiert;      crepo;     1751101789\n",
       "111       mürrisch      grumpy     1751101789\n",
       "112      bisweilen   sometimes     1751101789\n",
       "113        üppigen        lush     1751101789\n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_gota_df(wordll_list, dest_list, path_cder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
