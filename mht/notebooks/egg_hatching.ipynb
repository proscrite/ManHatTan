{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "41db59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle, sample\n",
    "import stanza\n",
    "from bidi.algorithm import get_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bb19794c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>n_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>word_ll</th>\n",
       "      <th>word_ul</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>...</th>\n",
       "      <th>mdt_history</th>\n",
       "      <th>mdt_correct</th>\n",
       "      <th>mrt_history</th>\n",
       "      <th>mrt_correct</th>\n",
       "      <th>wdt_history</th>\n",
       "      <th>wdt_correct</th>\n",
       "      <th>wrt_history</th>\n",
       "      <th>wrt_correct</th>\n",
       "      <th>speed</th>\n",
       "      <th>rebag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_ul</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scholarship</th>\n",
       "      <td>0.714</td>\n",
       "      <td>190</td>\n",
       "      <td>1743319778</td>\n",
       "      <td>0</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>מלגה</td>\n",
       "      <td>scholarship</td>\n",
       "      <td>מלגה/מלגה&lt;NOUN&gt;Fem|Sing|</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intention</th>\n",
       "      <td>0.857</td>\n",
       "      <td>98</td>\n",
       "      <td>1744291702</td>\n",
       "      <td>971924</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>כונה</td>\n",
       "      <td>intention</td>\n",
       "      <td>כונה/כונה&lt;VERB&gt;Masc|PUAL|Sing|3|Past|Pass|</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>towel</th>\n",
       "      <td>1.000</td>\n",
       "      <td>501</td>\n",
       "      <td>1744182216</td>\n",
       "      <td>862438</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>מגבת</td>\n",
       "      <td>towel</td>\n",
       "      <td>מגבת/גיבת&lt;VERB&gt;Fem|PAAL|Sing|1,2,3|Part|Act|</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to arrive</th>\n",
       "      <td>0.950</td>\n",
       "      <td>280</td>\n",
       "      <td>1747120372</td>\n",
       "      <td>3800594</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>להגיע</td>\n",
       "      <td>to arrive</td>\n",
       "      <td>להגיע/הגיע&lt;VERB&gt;HIFIL|Inf|Act|</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade</th>\n",
       "      <td>1.000</td>\n",
       "      <td>390</td>\n",
       "      <td>1744122447</td>\n",
       "      <td>802669</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>ציון</td>\n",
       "      <td>Grade</td>\n",
       "      <td>ציון/ציון&lt;PROPN&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Army</th>\n",
       "      <td>0.000</td>\n",
       "      <td>90</td>\n",
       "      <td>1746629700</td>\n",
       "      <td>0</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>צבא</td>\n",
       "      <td>Army</td>\n",
       "      <td>צבא/צבא&lt;NOUN&gt;Masc|Sing|</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cute</th>\n",
       "      <td>0.000</td>\n",
       "      <td>572</td>\n",
       "      <td>1746629700</td>\n",
       "      <td>0</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>חמוד</td>\n",
       "      <td>Cute</td>\n",
       "      <td>חמוד/חמוד&lt;ADJ&gt;Masc|Sing|</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you asked</th>\n",
       "      <td>0.000</td>\n",
       "      <td>163</td>\n",
       "      <td>1746629700</td>\n",
       "      <td>0</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>ביקשת</td>\n",
       "      <td>you asked</td>\n",
       "      <td>ביקשת/ביקש&lt;VERB&gt;Masc|PIEL|Sing|1|Past|Act|</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shower</th>\n",
       "      <td>0.000</td>\n",
       "      <td>150</td>\n",
       "      <td>1746629700</td>\n",
       "      <td>0</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>להתקלח</td>\n",
       "      <td>shower</td>\n",
       "      <td>להתקלח/התקלח&lt;VERB&gt;HITPAEL|Inf|</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insolent</th>\n",
       "      <td>0.000</td>\n",
       "      <td>561</td>\n",
       "      <td>1746629700</td>\n",
       "      <td>0</td>\n",
       "      <td>pablo</td>\n",
       "      <td>iw</td>\n",
       "      <td>en</td>\n",
       "      <td>חצוף</td>\n",
       "      <td>insolent</td>\n",
       "      <td>חצוף/חצוף&lt;ADJ&gt;Masc|Sing|</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             p_recall  n_id   timestamp    delta user_id learning_language  \\\n",
       "word_ul                                                                      \n",
       "scholarship     0.714   190  1743319778        0   pablo                iw   \n",
       "intention       0.857    98  1744291702   971924   pablo                iw   \n",
       "towel           1.000   501  1744182216   862438   pablo                iw   \n",
       "to arrive       0.950   280  1747120372  3800594   pablo                iw   \n",
       "Grade           1.000   390  1744122447   802669   pablo                iw   \n",
       "...               ...   ...         ...      ...     ...               ...   \n",
       "Army            0.000    90  1746629700        0   pablo                iw   \n",
       "Cute            0.000   572  1746629700        0   pablo                iw   \n",
       "you asked       0.000   163  1746629700        0   pablo                iw   \n",
       "shower          0.000   150  1746629700        0   pablo                iw   \n",
       "insolent        0.000   561  1746629700        0   pablo                iw   \n",
       "\n",
       "            ui_language word_ll      word_ul  \\\n",
       "word_ul                                        \n",
       "scholarship          en    מלגה  scholarship   \n",
       "intention            en    כונה    intention   \n",
       "towel                en    מגבת        towel   \n",
       "to arrive            en   להגיע    to arrive   \n",
       "Grade                en    ציון        Grade   \n",
       "...                 ...     ...          ...   \n",
       "Army                 en     צבא         Army   \n",
       "Cute                 en    חמוד         Cute   \n",
       "you asked            en   ביקשת    you asked   \n",
       "shower               en  להתקלח       shower   \n",
       "insolent             en    חצוף     insolent   \n",
       "\n",
       "                                            lexeme_string  ...  mdt_history  \\\n",
       "word_ul                                                    ...                \n",
       "scholarship                      מלגה/מלגה<NOUN>Fem|Sing|  ...            5   \n",
       "intention      כונה/כונה<VERB>Masc|PUAL|Sing|3|Past|Pass|  ...            4   \n",
       "towel        מגבת/גיבת<VERB>Fem|PAAL|Sing|1,2,3|Part|Act|  ...            2   \n",
       "to arrive                  להגיע/הגיע<VERB>HIFIL|Inf|Act|  ...           13   \n",
       "Grade                                    ציון/ציון<PROPN>  ...            6   \n",
       "...                                                   ...  ...          ...   \n",
       "Army                              צבא/צבא<NOUN>Masc|Sing|  ...            0   \n",
       "Cute                             חמוד/חמוד<ADJ>Masc|Sing|  ...            0   \n",
       "you asked      ביקשת/ביקש<VERB>Masc|PIEL|Sing|1|Past|Act|  ...            0   \n",
       "shower                     להתקלח/התקלח<VERB>HITPAEL|Inf|  ...            0   \n",
       "insolent                         חצוף/חצוף<ADJ>Masc|Sing|  ...            0   \n",
       "\n",
       "             mdt_correct  mrt_history  mrt_correct  wdt_history  wdt_correct  \\\n",
       "word_ul                                                                        \n",
       "scholarship            5            0            0            2            0   \n",
       "intention              4            0            0            2            2   \n",
       "towel                  2            0            0            4            4   \n",
       "to arrive             12            0            0            5            5   \n",
       "Grade                  6            0            0            0            0   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "Army                   0            0            0            0            0   \n",
       "Cute                   0            0            0            0            0   \n",
       "you asked              0            0            0            0            0   \n",
       "shower                 0            0            0            0            0   \n",
       "insolent               0            0            0            0            0   \n",
       "\n",
       "             wrt_history  wrt_correct   speed  rebag  \n",
       "word_ul                                               \n",
       "scholarship            0            0  0.1459   True  \n",
       "intention              0            0  0.0835   True  \n",
       "towel                  0            0  0.1115   True  \n",
       "to arrive              0            0  0.1518   True  \n",
       "Grade                  0            0  0.1102   True  \n",
       "...                  ...          ...     ...    ...  \n",
       "Army                   0            0  0.0000  False  \n",
       "Cute                   0            0  0.0000  False  \n",
       "you asked              0            0  0.0000  False  \n",
       "shower                 0            0  0.0000  False  \n",
       "insolent               0            0  0.0000  False  \n",
       "\n",
       "[293 rows x 25 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eggpath = '/Users/pabloherrero/Documents/ManHatTan/mht/data/processed/EGGs/hebrew_db_team_מפלצת.eggs'\n",
    "lippath = '/Users/pabloherrero/Documents/ManHatTan/mht/data/processed/LIPSTICK/hebrew_db.lip'\n",
    "egg = pd.read_csv(eggpath)\n",
    "egg = egg.set_index('word_ul', drop=False)\n",
    "\n",
    "lipstick = pd.read_csv(lippath)\n",
    "lipstick = lipstick.set_index('word_ul', drop=False)\n",
    "lipstick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47f83c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_nid(lipstick):\n",
    "    \"\"\"Get a random n_id from the available ones in stage 0\"\"\"\n",
    "    # Ensure that lipstick is initialized\n",
    "    if lipstick.empty:\n",
    "        raise ValueError(\"Lipstick DataFrame is empty. Please initialize it first.\")\n",
    "    \n",
    "    # Get the path to the stage 0 n_ids\n",
    "    pathnid = '/Users/pabloherrero/Documents/ManHatTan/mht/gui/Graphics/index_stage_0.csv'\n",
    "    stage0_nids = pd.read_csv(pathnid, index_col=None).T.values[0]\n",
    "    available_nids = np.setdiff1d(stage0_nids, lipstick['n_id'].values)\n",
    "    random_nid = sample(list(available_nids), 1)[0]\n",
    "    \n",
    "    return random_nid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "68bbd15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_lexeme(lip):\n",
    "    \"\"\"Get lexeme for a single LIPSTICK entry\"\"\"\n",
    "\n",
    "    lang = lip['learning_language']\n",
    "    token = lip['word_ll']\n",
    "\n",
    "    if lang == 'iw':\n",
    "        lang = 'he'\n",
    "\n",
    "    nlp = stanza.Pipeline(lang=lang, processors='tokenize,pos,lemma,depparse', tokenize_pretokenized=True)\n",
    "    # nlp = stanza.Pipeline(lang=lang, processors='tokenize,mwt,pos,lemma,depparse')\n",
    "    print(f'Token: {token}')\n",
    "    print(f'Type token[0]: {type(token)}')\n",
    "\n",
    "    doc = nlp(token)\n",
    "    for sent in doc.sentences:\n",
    "        lexeme_string = ''\n",
    "        # print(len(sent.words))\n",
    "        for word in sent.words:\n",
    "            lexeme_string += word.text \n",
    "            if word.lemma:\n",
    "                lexeme_string += '/' + word.lemma \n",
    "            if word.upos:\n",
    "                lexeme_string += '<' + word.upos + '>'\n",
    "            if word.feats:\n",
    "                feats = word.feats.split('|')\n",
    "                lexeme_string += ''.join(feat.split('=')[1] +'|' for feat in feats)\n",
    "            if word.deprel != 'root':\n",
    "                lexeme_string +=  ',' + word.deprel\n",
    "    return lexeme_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b61b5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_hatched_egg(egg : pd.DataFrame, word_ul : str, lipstick: pd.DataFrame, flag_lexeme = False):\n",
    "    \"\"\"Initialize a new entry in the egg dataframe for a specific word.\"\"\"\n",
    "    egg_entry = egg.loc[word_ul].copy()\n",
    "    \n",
    "    random_nid = get_random_nid(lipstick)\n",
    "    egg_entry['n_id'] = random_nid\n",
    "\n",
    "    egg_entry['session_seen'] = 0\n",
    "    egg_entry['session_correct'] = 0\n",
    "    egg_entry['p_pred'] = 0\n",
    "    egg_entry['rebag'] = False\n",
    "    if flag_lexeme:\n",
    "        lexeme = get_single_lexeme(egg_entry)\n",
    "        egg_entry['lexeme_string'] = lexeme\n",
    "    else:\n",
    "        egg_entry['lexeme_string'] = 'No lexeme'\n",
    "    return egg_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ce52965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 19:00:58 WARNING: Language he package default expects mwt, which has been added\n",
      "2025-06-12 19:00:58 INFO: Loading these models for language: he (Hebrew):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | htb     |\n",
      "| mwt       | htb     |\n",
      "| pos       | htb     |\n",
      "| lemma     | htb     |\n",
      "| depparse  | htb     |\n",
      "=======================\n",
      "\n",
      "2025-06-12 19:00:58 INFO: Use device: cpu\n",
      "2025-06-12 19:00:58 INFO: Loading: tokenize\n",
      "2025-06-12 19:00:58 INFO: Loading: mwt\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/mwt/trainer.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-12 19:00:58 INFO: Loading: pos\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/pos/trainer.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/common/pretrain.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "2025-06-12 19:00:59 INFO: Loading: lemma\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/lemma/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-12 19:00:59 INFO: Loading: depparse\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/depparse/trainer.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-12 19:00:59 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type token[0]: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# self.word_ul\n",
    "word_ul = 'cat'\n",
    "\n",
    "egg_entry = init_hatched_egg(egg, word_ul, lipstick=lipstick, flag_lexeme=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5df996d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_egg_to_lipstick(egg_entry, lipstick):\n",
    "    \"\"\"Add a new egg entry to the lipstick DataFrame.\"\"\"\n",
    "    # Ensure that egg_entry is a Series with the correct index\n",
    "    if not isinstance(egg_entry, pd.Series):\n",
    "        raise ValueError(\"egg_entry must be a pandas Series.\")\n",
    "    # Check if the word_ul exists in lipstick\n",
    "    if egg_entry['word_ul'] in lipstick.index:\n",
    "        raise ValueError(f\"Word '{egg_entry['word_ul']}' already exists in lipstick DataFrame.\")\n",
    "    # Add the egg entry to the lipstick DataFrame\n",
    "    \n",
    "    lipstick = lipstick.set_index('word_ul', drop=False)\n",
    "    new_lipstick = pd.concat([lipstick, egg_entry.to_frame().T])\n",
    "    # Reset the index to ensure word_ul is the index\n",
    "    new_lipstick = new_lipstick.reset_index(drop=True)\n",
    "\n",
    "    return new_lipstick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "23a4da0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 19:02:17 WARNING: Language he package default expects mwt, which has been added\n",
      "2025-06-12 19:02:17 INFO: Loading these models for language: he (Hebrew):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | htb     |\n",
      "| mwt       | htb     |\n",
      "| pos       | htb     |\n",
      "| lemma     | htb     |\n",
      "| depparse  | htb     |\n",
      "=======================\n",
      "\n",
      "2025-06-12 19:02:17 INFO: Use device: cpu\n",
      "2025-06-12 19:02:17 INFO: Loading: tokenize\n",
      "2025-06-12 19:02:17 INFO: Loading: mwt\n",
      "2025-06-12 19:02:17 INFO: Loading: pos\n",
      "2025-06-12 19:02:17 INFO: Loading: lemma\n",
      "2025-06-12 19:02:17 INFO: Loading: depparse\n",
      "2025-06-12 19:02:17 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: חתול\n",
      "Type token[0]: <class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'חתול/חתול<NOUN>Masc|Sing|'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_single_lexeme(egg_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b13d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_lipstick.to_csv(lippath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3157028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_random_nid():\n",
    "    \"\"\"Test the get_random_nid function.\"\"\"\n",
    "    random_nid = get_random_nid(lipstick)\n",
    "    assert isinstance(random_nid, np.int64), \"Random n_id should be an integer.\"\n",
    "    assert random_nid not in lipstick['n_id'].values, \"Random n_id should not be in the lipstick DataFrame.\"\n",
    "\n",
    "def test_init_hatched_egg():\n",
    "    \"\"\"Test the init_hatched_egg function.\"\"\"\n",
    "    word_ul = 'cat'\n",
    "    egg_entry = init_hatched_egg(egg, word_ul, lipstick=lipstick, flag_lexeme=True)\n",
    "    \n",
    "    assert egg_entry['word_ul'] == word_ul, \"Word_ul should match the input word.\"\n",
    "    assert 'n_id' in egg_entry, \"Egg entry should contain n_id.\"\n",
    "    assert 'session_seen' in egg_entry, \"Egg entry should contain session_seen.\"\n",
    "    assert 'session_correct' in egg_entry, \"Egg entry should contain session_correct.\"\n",
    "    assert 'p_pred' in egg_entry, \"Egg entry should contain p_pred.\"\n",
    "    assert 'rebag' in egg_entry, \"Egg entry should contain rebag.\"\n",
    "    assert 'lexeme_string' in egg_entry, \"Egg entry should contain lexeme_string.\"\n",
    "    assert isinstance(egg_entry['lexeme_string'], str), \"Lexeme string should be a string.\"\n",
    "\n",
    "def test_add_egg_to_lipstick():\n",
    "    \"\"\"Test the add_egg_to_lipstick function.\"\"\"\n",
    "    egg_entry = init_hatched_egg(egg, 'cat', lipstick=lipstick, flag_lexeme=True)\n",
    "    new_lipstick = add_egg_to_lipstick(egg_entry, lipstick)\n",
    "    \n",
    "    assert 'cat' in new_lipstick['word_ul'].values, \"New word should be added to lipstick DataFrame.\"\n",
    "    assert new_lipstick.shape[0] == lipstick.shape[0] + 1, \"New lipstick DataFrame should have one more row than the original.\"\n",
    "    assert new_lipstick.loc[new_lipstick['word_ul'] == 'cat', 'n_id'].values[0] == egg_entry['n_id'], \"n_id should match the egg entry.\"\n",
    "\n",
    "def test_get_single_lexeme():\n",
    "    \"\"\"Test the get_single_lexeme function.\"\"\"\n",
    "    lip_entry = lipstick.iloc[0]  # Get the first entry in the lipstick DataFrame\n",
    "    lexeme_string = get_single_lexeme(lip_entry)\n",
    "    \n",
    "    assert isinstance(lexeme_string, str), \"Lexeme string should be a string.\"\n",
    "    assert len(lexeme_string) > 0, \"Lexeme string should not be empty.\"\n",
    "    print(f\"Lexeme string for {lip_entry['word_ll']}: {get_display(lexeme_string)}\")\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"Run all tests.\"\"\"\n",
    "    test_get_random_nid()\n",
    "    test_init_hatched_egg()\n",
    "    test_add_egg_to_lipstick()\n",
    "    print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4c58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 19:14:38 WARNING: Language he package default expects mwt, which has been added\n",
      "2025-06-12 19:14:38 INFO: Loading these models for language: he (Hebrew):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | htb     |\n",
      "| mwt       | htb     |\n",
      "| pos       | htb     |\n",
      "| lemma     | htb     |\n",
      "| depparse  | htb     |\n",
      "=======================\n",
      "\n",
      "2025-06-12 19:14:38 INFO: Use device: cpu\n",
      "2025-06-12 19:14:38 INFO: Loading: tokenize\n",
      "2025-06-12 19:14:38 INFO: Loading: mwt\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/mwt/trainer.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-12 19:14:38 INFO: Loading: pos\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/pos/trainer.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/common/pretrain.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "2025-06-12 19:14:38 INFO: Loading: lemma\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/lemma/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-12 19:14:39 INFO: Loading: depparse\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/depparse/trainer.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-12 19:14:39 INFO: Done loading processors!\n",
      "2025-06-12 19:14:39 WARNING: Language he package default expects mwt, which has been added\n",
      "2025-06-12 19:14:39 INFO: Loading these models for language: he (Hebrew):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | htb     |\n",
      "| mwt       | htb     |\n",
      "| pos       | htb     |\n",
      "| lemma     | htb     |\n",
      "| depparse  | htb     |\n",
      "=======================\n",
      "\n",
      "2025-06-12 19:14:39 INFO: Use device: cpu\n",
      "2025-06-12 19:14:39 INFO: Loading: tokenize\n",
      "2025-06-12 19:14:39 INFO: Loading: mwt\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/mwt/trainer.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-12 19:14:39 INFO: Loading: pos\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/pos/trainer.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/common/pretrain.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: חתול\n",
      "Type token[0]: <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 19:14:39 INFO: Loading: lemma\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/lemma/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-12 19:14:39 INFO: Loading: depparse\n",
      "/Users/pabloherrero/Library/Python/3.9/lib/python/site-packages/stanza/models/depparse/trainer.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-12 19:14:39 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: חתול\n",
      "Type token[0]: <class 'str'>\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
